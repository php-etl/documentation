<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="utf-8">
  <title>Gyroscops </title>

  <meta name="generator" content="Hugo 0.121.2">

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- ** Plugins Needed for the Project ** -->
  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://php-etl.github.io/documentation/plugins/bootstrap/bootstrap.min.css">

  <!-- themefy-icon -->
  <link rel="stylesheet" href="https://php-etl.github.io/documentation/plugins/themify-icons/themify-icons.css">

  <!-- highlight -->
  <link rel="stylesheet" href="https://php-etl.github.io/documentation/plugins/highlight/hybrid.css">

  <!--Favicon-->
  <link rel="icon" href="https://php-etl.github.io/documentation/favicon.png" type="image/x-icon">

  <!-- fonts -->
  <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700&display=swap" rel="stylesheet">

  <style>
  :root{
    --primary-color: #22014f;
    --primary-color-lighten: #f2e9fe;
    --secondary-color:#fe8507;
    --body-color:#ddd;
    --text-color:#666;
    --text-color-dark:#333;
    --text-color-light:#eee;
    --white-color:#fff;
    --light-color:#eee;
    --font-family:Lato;
  }
  </style>

<!-- Main Stylesheet -->

<link href="https://php-etl.github.io/documentation/css/style.min.css" rel="stylesheet" media="screen"/>

<!-- jquiry -->
<script src="https://php-etl.github.io/documentation/plugins/jquery/jquery-1.12.4.js"></script>

<!-- jquary ui -->
<script src="https://php-etl.github.io/documentation/plugins/jquery/jquery-ui.js"></script>

<!-- Bootstrap JS -->
<script src="https://php-etl.github.io/documentation/plugins/bootstrap/bootstrap.min.js"></script>

<!-- match-height JS -->
<script src="https://php-etl.github.io/documentation/plugins/match-height/jquery.matchHeight-min.js"></script>

<!-- highlight -->
<script src="https://php-etl.github.io/documentation/plugins/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



</head>


  <body>

    <nav class="navbar navbar-expand-md bg-light">
  <div class="container">
    <a class="navbar-brand" href="/documentation">




      <div class="navbar-brand">
        <img class="img-fluid" src="https://php-etl.github.io/documentation/logo-web.svg "
          alt="Gyroscops">
      </div>


    </a>
    <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation"
      aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse text-center" id="navigation">
      <ul class="navbar-nav ml-auto">


        <li class="nav-item dropdown">
          <span class="nav-link dropdown-toggle text-dark" href="#" role="button" data-toggle="dropdown"
            aria-haspopup="true" aria-expanded="false">
            Getting Started
          </span>
          <div class="dropdown-menu">

            <a class="dropdown-item" href="/documentation/getting-started/environment-setup">Environment Setup</a>

            <a class="dropdown-item" href="/documentation/getting-started/installation">Installation</a>

            <a class="dropdown-item" href="/documentation/getting-started/writing-configuration">Writing Configuration</a>

            <a class="dropdown-item" href="/documentation/getting-started/compilation">Compilation</a>

            <a class="dropdown-item" href="/documentation/getting-started/execution">Execution</a>

          </div>
        </li>



        <li class="nav-item dropdown">
          <span class="nav-link dropdown-toggle text-dark" href="#" role="button" data-toggle="dropdown"
            aria-haspopup="true" aria-expanded="false">
            Core concepts
          </span>
          <div class="dropdown-menu">

            <a class="dropdown-item" href="/documentation/core-concept/satellite">Satellites</a>

            <a class="dropdown-item" href="/documentation/core-concept/satellite/pipeline">Pipeline</a>

            <a class="dropdown-item" href="/documentation/core-concept/satellite/workflow">Workflow</a>

            <a class="dropdown-item" href="/documentation/core-concept/satellite/http-hook">HTTP Hook</a>

            <a class="dropdown-item" href="/documentation/core-concept/satellite/http-api">HTTP API</a>

            <a class="dropdown-item" href="/documentation/core-concept/satellite/action">Action</a>

          </div>
        </li>



        <li class="nav-item dropdown">
          <span class="nav-link dropdown-toggle text-dark" href="#" role="button" data-toggle="dropdown"
            aria-haspopup="true" aria-expanded="false">
            Connectivity
          </span>
          <div class="dropdown-menu">

            <a class="dropdown-item" href="/documentation/connectivity/akeneo">Akeneo</a>

            <a class="dropdown-item" href="/documentation/connectivity/csv">CSV files</a>

            <a class="dropdown-item" href="/documentation/connectivity/custom">Custom connector</a>

            <a class="dropdown-item" href="/documentation/connectivity/fast-map">FastMap</a>

            <a class="dropdown-item" href="/documentation/connectivity/ftp">FTP</a>

            <a class="dropdown-item" href="/documentation/connectivity/sftp">SFTP</a>

            <a class="dropdown-item" href="/documentation/connectivity/json">JSON</a>

            <a class="dropdown-item" href="/documentation/connectivity/spreadsheet">Spreadsheet files</a>

            <a class="dropdown-item" href="/documentation/connectivity/sql">SQL database</a>

            <a class="dropdown-item" href="/documentation/connectivity/sylius">Sylius</a>

            <a class="dropdown-item" href="/documentation/connectivity/prestashop">Prestashop</a>

            <a class="dropdown-item" href="/documentation/connectivity/filtering">Filtering, drop or reject</a>

            <a class="dropdown-item" href="/documentation/connectivity/batch">Batch</a>

            <a class="dropdown-item" href="/documentation/connectivity/magento-2">Magento 2</a>

            <a class="dropdown-item" href="/documentation/connectivity/zoho">Zoho CRM</a>

          </div>
        </li>



        <li class="nav-item dropdown">
          <span class="nav-link dropdown-toggle text-dark" href="#" role="button" data-toggle="dropdown"
            aria-haspopup="true" aria-expanded="false">
            Features
          </span>
          <div class="dropdown-menu">

            <a class="dropdown-item" href="/documentation/feature/services">Declaring services</a>

            <a class="dropdown-item" href="/documentation/feature/expression-language">Expression Language</a>

            <a class="dropdown-item" href="/documentation/feature/logger">Logging</a>

            <a class="dropdown-item" href="/documentation/feature/rejection">Rejection</a>

            <a class="dropdown-item" href="/documentation/feature/state">State</a>

          </div>
        </li>



        <li class="nav-item dropdown">
          <span class="nav-link dropdown-toggle text-dark" href="#" role="button" data-toggle="dropdown"
            aria-haspopup="true" aria-expanded="false">
            Cloud
          </span>
          <div class="dropdown-menu">

            <a class="dropdown-item" href="/documentation/cloud/usage">Usage</a>

          </div>
        </li>


      </ul>

    </div>
  </div>
</nav>

    <!-- header -->
    <header class="banner " data-background="https://php-etl.github.io/documentation/">
      <!-- banner -->
<div class="container section">
	<div class="row">
		<div class="col-lg-8 text-center mx-auto">
			<h1 class="text-dark mb-3">Gyroscops Documentation</h1>
			<p class="text-dark mb-4">Browse the documentation and knowledge base to start quickly with Gyroscops</p>
			<div class="position-relative">
				<input id="search" class="form-control" placeholder="Have a question? Just ask here or enter terms">
				<i class="ti-search search-icon"></i>




				<script>
					$(function() {
					var projects = [

						{
							value: "Lookup mapper",
							label: "<p>A lookup mapper is a class that implements Kiboko\\Contract\\Mapping\\CompiledMapperInterface.\nIts purpose is to merge the result of the lookup back into your line.\n$output is your line, and $input is the result of the lookup.\n\u0026lt;?php declare(strict_types=1); namespace Acme\\Custom; use Kiboko\\Contract\\Mapping\\CompiledMapperInterface; class LookupMapper implements CompiledMapperInterface { public function __invoke($input, $output = null) { $output[\u0026#39;actual_customer_id\u0026#39;] = $input[\u0026#39;id\u0026#39;]; return $output; } } </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/custom\/lookup_mapper\/"
						},

						{
							value: "Environment Setup",
							label: "<p>Gyroscops is a command line application written in PHP. To be able to use the application, you will need to fulfill the following requirements:\nPHP 8.2 or higher Before proceeding, make sure your computer has a PHP version higher than or equal to 8.2 installed.\nFor more information on how to install PHP, go to the official documentation.\nComposer 2 After installing PHP, you must ensure that Composer 2 is installed on your machine.\nFor more information on how to install Composer, go to the official documentation.\nDocker (optional) Gyroscops offers you the possibility to build your configurations as images that you can use in a dockerized environment. That\u0026rsquo;s why you may also need Docker.\nFor more information on how to install Docker, go to the official documentation.\nBefore v0.6.6 of php-etl\/satellite: JQ Jq, a JSON processor, is also required for satellites to generate their composer.json files.\nFor more information on how to install jq, go to the official documentation.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/getting-started\/environment-setup\/"
						},

						{
							value: "Declaring services",
							label: "<p> What is it for? Installation Usage Defining your arguments Making the service public Using method calls Using factories Using a service as an argument What is it for? Based on Symfony services, it is possible to inject objects into your pipeline or workflow. To learn more about services, please visit the official Symfony documentation.\nInstallation This plugin is already integrated into the Satellite package, so you can\u0026rsquo;t require it with the composer.\nUsage If you are using a very simple service, you can define it as follows:\nservices: App\\Foo\\Bar: ~ Defining your arguments services: App\\Foo\\Bar: arguments: - \u0026#39;my-file.csv\u0026#39; # it\u0026#39;s a string argument - { host: \u0026#34;localhost\u0026#34;, port: \u0026#39;8000\u0026#39; } # it\u0026#39;s an array argument - 1234 # it\u0026#39;s a integer argument In this example, the App\\Foo\\Bar service will have 3 parameters that will be passed into the __construct method of your class (in the order of writing).\nMaking the service public If you need to make a service public, use the public option which you set to true.\nservices: App\\Foo\\Bar: # ... public: true Using method calls To understand what calls are, go to the official call documentation.\nservices: App\\Foo\\Bar: # ... calls: - withUsername: [ \u0026#39;admin\u0026#39; ] Build a factory To understand how to use and create factories, go to the official call documentation.\nservices: App\\Foo\\Bar: # ... factory: class: App\\Class\\Bar method: extract arguments: - \u0026#39;@foo\u0026#39; Using a service as an argument It\u0026rsquo;s possible to use a service as an argument when declaring a service by using the service name preceded by @.\nservices: App\\Foo\\Foo: arguments: - \u0026#39;@App\\Foo\\Bar\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/services\/"
						},

						{
							value: "Akeneo plugin",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] Akeneo Plugin What is it ? Installation Usage Connecting to Akeneo Building an extractor Building a lookup Building a conditional lookup Building a loader Advanced Usage Filtering your search Using ExpressionLanguage Available resources What is it ? The Akeneo plugin aims at integration the Akeneo PHP clients into the Pipeline stack. This integration is compatible with both Akeneo Enterprise Edition client and the Akeneo Community Edition client.\nInstallation composer require php-etl\/akeneo-plugin:\u0026#39;*\u0026#39; Usage Connecting to Akeneo To establish a connection to your Akeneo PIM, you must specify its URL (api_url) and some connection identifiers (client_id, secret, username, password).\nakeneo: # ... client: api_url: \u0026#39;http:\/\/demo.akeneo.com\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;demo_9573\u0026#39; password: \u0026#39;516f3e3e5\u0026#39; To retrieve these identifiers, you need to add a connection in your Akeneo PIM.\nWarning: For the api_url option, you must remove the \/ at the end of your URL if there is one.\nBuilding an extractor In the configuration of your extractor, you must specify the type of resource (see available-resources) you will be working on and which method you want to use to retrieve your data.\nFor each resource, the following 3 methods are available :\nall : retrieves all data from a table get : retrieve a row from a table listPerPage : retrieves a set number of data from a table Depending on the resource and the method used, different options are available in the YAML configuration :\nResource Method Option(s) required All resources all No options required All resources get identifier All resources listPerPage No options required attributeOption all attribute_code attributeOption get attribute_code, code assetManager all asset_family_code assetManager get asset_family_code, asset_code productMediaFile, assetMediaFile get file akeneo: extractor: type: product method: all client: api_url: \u0026#39;http:\/\/demo.akeneo.com\/\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;demo_9573\u0026#39; password: \u0026#39;516f3e3e5\u0026#39; Building a lookup In some cases, you will need to perform some lookups to append to the data already read some complementary data coming from a secondary data source; this is called a lookup.\nIn the configuration of your lookup, you must specify the type of resource you will be working on and which method you want to use to retrieve your data.\nYou can retrieve the list of available resources here.\nThe options available are the same as for the loader.\nThe merge option allows you to add data to your dataset, in a sense merging your actual dataset with your new data.\nThe map option comes from the FastMap plugin, you may need to read its documentation to understand how to use it properly.\nakeneo: lookup: type: product method: all merge: map: - field: \u0026#39;[options]\u0026#39; expression: \u0026#39;lookup[\u0026#34;code\u0026#34;]\u0026#39; client: api_url: \u0026#39;http:\/\/demo.akeneo.com\/\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;demo_9573\u0026#39; password: \u0026#39;516f3e3e5\u0026#39; Building a conditional lookup The conditional lookup is very similar to a regular lookup, at the difference that the lookup will be performed only if some conditions are full-filled.\nIn this configuration, you will find options very similar to a standard lookup, difference being on 2 new levels of encapsulation, one of them containing the condition.\nakeneo: lookup: conditional: - condition: \u0026#39;@=(input[\u0026#34;type\u0026#34;] in [\u0026#34;pim_catalog_simpleselect\u0026#34;, \u0026#34;pim_catalog_multipleselect\u0026#34;])\u0026#39; type: attributeOption code: \u0026#39;@=input[\u0026#34;code\u0026#34;]\u0026#39; method: listPerPage search: - { field: enabled, operator: \u0026#39;=\u0026#39;, value: \u0026#39;@=input[\u0026#34;code\u0026#34;]\u0026#39;, scope: \u0026#39;@=input[\u0026#34;code\u0026#34;]\u0026#39;, locale: \u0026#39;@=input[\u0026#34;fr_FR\u0026#34;]\u0026#39; } merge: map: - field: \u0026#39;[options]\u0026#39; expression: \u0026#39;join(\u0026#34;|\u0026#34;, lookup[\u0026#34;code\u0026#34;])\u0026#39; - condition: \u0026#39;@=(input[\u0026#34;type\u0026#34;] in [\u0026#34;akeneo_reference_entity\u0026#34;, \u0026#34;akeneo_reference_entity_collection\u0026#34;])\u0026#39; type: referenceEntityRecord code: \u0026#39;@=input[\u0026#34;code\u0026#34;]\u0026#39; method: listPerPage search: - { field: enabled, operator: \u0026#39;=\u0026#39;, value: \u0026#39;@=input[\u0026#34;code\u0026#34;]\u0026#39;, scope: \u0026#39;@=input[\u0026#34;code\u0026#34;]\u0026#39;, locale: \u0026#39;@=input[\u0026#34;fr_FR\u0026#34;]\u0026#39; } merge: map: - field: \u0026#39;[options]\u0026#39; expression: \u0026#39;join(\u0026#34;|\u0026#34;, lookup[\u0026#34;code\u0026#34;])\u0026#39; # ... Building a loader In the configuration of your loader, you must specify the type of resource (see available-resources) you are going to write and which method you want to use to insert your data.\nFor each resource, the following 4 methods are available :\ncreate: insert a new resource upsert: will try to update the resource, otherwise the resource will be created upsertList: will try to update a resources list, otherwise the resources will be created delete: delete a resource from the table Depending on the resource and the method used, different options are available in the YAML configuration :\nResource Method Option(s) required All resources upsert code All resources upsertList No options required referenceEntityRecord upsert reference_entity, code referenceEntityRecord upsertList reference_entity referenceEntityAttributeOption upsert reference_entity, reference_entity_attribute, code referenceEntityAttributeOption upsertList reference_entity, reference_entity_attribute attributeOption upsert attribute_code, code attributeOption upsertList attribute_code akeneo: loader: type: products method: create client: api_url: \u0026#39;http:\/\/demo.akeneo.com\/\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;demo_9573\u0026#39; password: \u0026#39;516f3e3e5\u0026#39; Advanced Usage Filtering your search In some cases, you may only want to retrieve data that matches specific criteria.\nWhen performing a search, you need to specify certain options :\nfield : the field you want to search operator : the operator of your search value : the value of the field you want to search Other options are available but are not essential in your search :\nscope : scope in which you search locale : code of the locale you are looking for akeneo: extractor: # ... search: - { field: enabled, operator: \u0026#39;=\u0026#39;, value: true } - { field: completeness, operator: \u0026#39;\u0026gt;\u0026#39;, value: 70, scope: ecommerce } You may need to read the filtering documentation of Akeneo API\nUsing ExpressionLanguage The plugin takes into account the ExpressionLanguage component provided by Symfony.\nWe have also provided custom expression to use when mapping your data.\nakeneo: expression_language: - \u0026#39;Kiboko\\Component\\ExpressionLanguage\\Akeneo\\AkeneoFilterProvider\u0026#39; # ... Available resources Resources Akeneo\u0026rsquo;s Edition(s) product Community, Growth, Enterprise category Community, Growth, Enterprise attribute Community, Growth, Enterprise attributeOption Community, Growth, Enterprise attributeGroup Community, Growth, Enterprise family Community, Growth, Enterprise productMediaFile Community, Growth, Enterprise locale Community, Growth, Enterprise channel Community, Growth, Enterprise currency Community, Growth, Enterprise measureFamily Community, Growth, Enterprise associationType Community, Growth, Enterprise familyVariant Community, Growth, Enterprise productModel Community, Growth, Enterprise publishedProduct Enterprise productModelDraft Enterprise productDraft Enterprise asset Enterprise assetCategory Enterprise assetTag Enterprise referenceEntityRecord Enterprise referenceEntityAttribute Enterprise referenceEntityAttributeOption Enterprise referenceEntity Enterprise </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/akeneo\/plugin\/"
						},

						{
							value: "Akeneo",
							label: "<p>The packages listed below aims at the integration of Akeneo PIM into the ETL Pipeline and Satellite stacks.\nThe tools built for Akeneo is composed of ETL capacities and data processing functions to be used in Fast Map.\nThe Akeneo plugin for ETL Pipeline This plugin will enable Akeneo connectivity to the ETL Pipeline, in order to read and write from and to Akeneo PIM. This integration is compatible with both Akeneo Enterprise Edition client and the Akeneo Community Edition client.\nSee detailed documentation\nThe Akeneo expression functions This plugin will extend the Fast Map data processing library with new functions dedicated to Akeneo-specific data formats and concepts.\nSee detailed documentation\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/akeneo\/"
						},

						{
							value: "Satellites",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] Building a satellite Setting up the Adapter Using Docker Using the file system Configure Composer Setting up the runtime Configuration formats Building Building locally Migration from version 0.2 and earlier Importing external files A satellite is the program that will execute your data flows. Depending on the type, it can be executed periodically or act as a microservice.\nIt can be deployed in a various list of infrastructure types, including LAMP stacks and container-aware stacks.\nIn the context of Gyroscops, a satellite can either be a Pipeline, a Workflow (containing multiple Pipelines and Actions), a HTTP Hook or an API.\nThose programs are called Satellites to reflect the fact that they need to operate very close from the main application in order to enhance their data connectivity Building a satellite The configuration of your satellite must be defined in a yaml file.\nA single file can describe several satellites. Each satellite is identified by a code (my_satellite in the following example) and has a label.\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first satellite\u0026#39; #... Setting up the Adapter Next, you should declare the Docker image or the directory inside which you want to build the satellite.\nIf you are using Gyroscops Cloud, you can ignore this step and directly go to the next chapter.\nUsing Docker To use a Docker image to build your satellite, implement the docker key with its configuration options :\nfrom : determines the image on which your code will run workdir : define the working directory of a Docker container tags : determines the references to the Docker images version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; docker: from: php:8.0-cli-alpine workdir: \/var\/www\/html tags: - acmeinc\/my-satellite:latest - acmeinc\/my-satellite:1.0.0 #... Here, we chose to use the php:8.0-cli-alpine base image on which our code will be executed. You could use any Docker image of your choice, however you will need to have a PHP runtime available, in a compatible version: \u0026gt;=8.0 with the CLI SAPI.\nUsing the file system To build your satellite inside your file system, implement the filesystem key.\nThe filesystem key is accompanied by a path key which determines the path of the microservice to be built.\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; filesystem: path: ..\/build # path to the build directory, relative to the YAML file #... Add custom code without a Composer package Sometimes you need to use a custom class but you can\u0026rsquo;t add a composer package, or creating this package is a disproportional effort. In this cas you have the copy options under the adapter.\nSupported by Docker and Filesystem adapters.\nThe build will copy files you list. If you use a class with a namespace, you will need to add the namespace to the autoloading specification.\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; filesystem: copy: - from: \u0026#39;..\/Foo\/Bar\u0026#39; to: \u0026#39;..\/build\/Foo\/Bar\u0026#39; path: ..\/build # path to the build directory, relative to the YAML file #... version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; docker: from: php:8.0-cli-alpine workdir: \/var\/www\/html tags: - acmeinc\/my-satellite:latest - acmeinc\/my-satellite:1.0.0 copy: - from: \u0026#39;..\/Foo\/Bar\u0026#39; to: \u0026#39;.\/src\/Foo\/Bar\u0026#39; #... Configure Composer It\u0026rsquo;s possible to declare the Composer dependencies, autoloads, repositories and auths that our microservice needs with the composer key.\nIf you instead wish to use your own composer.json to define the requirements and autoloads, set the option from_local to true, and jump to the next chapter. This will copy composer.json, and optionally composer.lock, if they are present next to your YAML configuration file:\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... composer: from_local: true Dependencies The require parameter allows to add all the packages, written as package_name:version, that your microservice needs.\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... composer: require: - \u0026#34;foo\/bar:^0.2\u0026#34; Tip : This part is not mandatory. If you do not configure it, these packages (php-etl\/pipeline-contracts, php-etl\/pipeline, php-etl\/pipeline-console-runtime, php-etl\/workflow-console-runtime, psr\/log, monolog\/monolog, symfony\/console, symfony\/dependency-injection) will be installed automatically.\nAutoload The autoload parameter is optional and allows you to configure your autoloader by specifying one or more namespaces and directories paths as if you were directly in the composer.json.\nEvery autoloading configuration shall be in the following format:\nnamespace: namespace of your files paths: directories in which the files to be loaded are located version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... composer: autoload: psr4: - namespace: \u0026#34;Pipeline\\\\\u0026#34; paths: [\u0026#34;\u0026#34;] Repositories The repositories parameter is optional. It allows you to use repositories that are not hosted on packagist.org.\nEach repository should have the following configuration fields:\nname: the name of your repository url: the url of your repository type: the type of your repository (vcs, composer, package, etc\u0026hellip;) version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... composer: repositories: - { name: \u0026#39;private-packagist\u0026#39;, url: \u0026#39;https:\/\/repo.packagist.com\/package\/\u0026#39;, type: \u0026#39;composer\u0026#39; } Auth The auth parameter is optional and allows you to use registries that are not public and must be accessed through an authentication. The parameter is the way for you to tell composer how to authenticate to the registry server.\nEach auth can have the following configuration fields:\nurl: the url of your repository token: when you use a connection via token, you must use this field version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... composer: auth: - { url: \u0026#39;http-basic.kiboko.repo.packagist.com\u0026#39;, token: \u0026#39;0fe8828b23371406295ca2b72634c0a3df2431c4787df0173ea051a0c639\u0026#39; } Notice : Currently, the only way to identify to a repository is to use tokens. Support for other authentication methods is in our backlog.\nSetting up the runtime Now that we have made our environment prepared for our satellite, we will declare the way we want our pipeline to handle our data flows.\nThere are 4 types of runtimes, you will have to choose one depending on your needs:\nname description details pipeline The satellite will be operating a data pipeline, executed in the backend that can be executed as a cron job. Pipeline documentation page workflow The satellite will be orchestrating multiple pipelines, executed in the backend that can be executed as a cron job Workflow documentation page http_hook The satellite will be operating an API on a single URL route. http_hook is used for webhooks. A webhook is a POST request sent to a URL. It\u0026rsquo;s considered to be a mean for one application to provide other applications with real-time information HTTP Hook documentation page http_api The satellite will be operating an API on multiple URL routes. http_api is used for REST API. HTTP API documentation page pipeline workflow http_hook http_api version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... pipeline: code: \u0026#39;my-first-pipeline\u0026#39; steps: - akeneo: extractor: type: category method: all client: api_url: \u0026#39;@=env(\u0026#34;AKENEO_URL\u0026#34;)\u0026#39; client_id: \u0026#39;@=env(\u0026#34;AKENEO_CLIENT_ID\u0026#34;)\u0026#39; secret: \u0026#39;@=env(\u0026#34;AKENEO_CLIENT_SECRET\u0026#34;)\u0026#39; username: \u0026#39;@=env(\u0026#34;AKENEO_USERNAME\u0026#34;)\u0026#39; password: \u0026#39;@=env(\u0026#34;AKENEO_PASSWORD\u0026#34;)\u0026#39; - csv: loader: file_path: categories.csv delimiter: \u0026#39;,\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; escape: \u0026#39;\\\\\u0026#39; version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... workflow: jobs: - pipeline: code: \u0026#39;my-first-pipeline\u0026#39; steps: - akeneo: extractor: type: category method: all client: api_url: \u0026#39;@=env(\u0026#34;AKENEO_URL\u0026#34;)\u0026#39; client_id: \u0026#39;@=env(\u0026#34;AKENEO_CLIENT_ID\u0026#34;)\u0026#39; secret: \u0026#39;@=env(\u0026#34;AKENEO_CLIENT_SECRET\u0026#34;)\u0026#39; username: \u0026#39;@=env(\u0026#34;AKENEO_USERNAME\u0026#34;)\u0026#39; password: \u0026#39;@=env(\u0026#34;AKENEO_PASSWORD\u0026#34;)\u0026#39; - csv: loader: file_path: categories.csv delimiter: \u0026#39;,\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; escape: \u0026#39;\\\\\u0026#39; - pipeline: code: \u0026#39;my-second-pipeline\u0026#39; steps: - akeneo: extractor: type: product method: all client: api_url: \u0026#39;@=env(\u0026#34;AKENEO_URL\u0026#34;)\u0026#39; client_id: \u0026#39;@=env(\u0026#34;AKENEO_CLIENT_ID\u0026#34;)\u0026#39; secret: \u0026#39;@=env(\u0026#34;AKENEO_CLIENT_SECRET\u0026#34;)\u0026#39; username: \u0026#39;@=env(\u0026#34;AKENEO_USERNAME\u0026#34;)\u0026#39; password: \u0026#39;@=env(\u0026#34;AKENEO_PASSWORD\u0026#34;)\u0026#39; - csv: loader: file_path: products.csv delimiter: \u0026#39;,\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; escape: \u0026#39;\\\u0026#39; version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... http_hook: path: \/my-hook expression: \u0026#39;input\u0026#39; pipeline: code: \u0026#39;my-first-pipeline\u0026#39; steps: - fastmap: map: - field: \u0026#39;[sku]\u0026#39; copy: \u0026#39;[product_name]\u0026#39; - field: \u0026#39;[id]\u0026#39; copy: \u0026#39;[product_code]\u0026#39; - csv: loader: file_path: \u0026#39;output.csv\u0026#39; version: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;My first Satellite\u0026#39; # ... http_api: path: \/my-api routes: - route: \/category expression: \u0026#39;input\u0026#39; pipeline: code: \u0026#39;my-first-pipeline\u0026#39; steps: - fastmap: map: - field: \u0026#39;[code]\u0026#39; copy: \u0026#39;[category_name]\u0026#39; - field: \u0026#39;[id]\u0026#39; copy: \u0026#39;[category_code]\u0026#39; - csv: loader: file_path: \u0026#39;category.csv\u0026#39; - route: \/product expression: \u0026#39;input\u0026#39; pipeline: code: \u0026#39;my-second-pipeline\u0026#39; steps: - fastmap: map: - field: \u0026#39;[sku]\u0026#39; copy: \u0026#39;[product_name]\u0026#39; - field: \u0026#39;[id]\u0026#39; copy: \u0026#39;[product_code]\u0026#39; - csv: loader: file_path: \u0026#39;product.csv\u0026#39; Configuration formats We are using YAML configuration format in all our example. However, you can similarly write your satellite configuration in the JSON format.\nBuild your satellite locally After declaring your satellite definition file, there is a command allowing you to generate the satellite program, either as a Docker image or files in your filesystem\n# Either use the satellite.yaml file in the current working directory php bin\/satellite build # or specify the path to the yaml file php bin\/satellite build path\/to\/satellite.yaml If you selected the Docker image variant, you can now execute this image in the way your container-aware environment If you are using Docker, you can do it with the following command: docker run --rm acmeinc\/my-satellite:latest my_satellite\nIf you selected the Filesystem variant, you can now execute this Satellite with the run:* commands provided:\nFor a Pipeline: bin\/satellite run:pipeline build\/ For a Workflow: bin\/satellite run:workflow build\/ Migration from version 0.2 and earlier If you are using a configuration for satellite prior to version 0.3, you should migrate your files ot the updated version. the new version 0.3 of the files definitions allows you to import files and create several satellites inside a single file.\nTo use this new version, you need to specify the version field in your configuration at the root of the file:\n# path\/to\/satellite.yaml version: 0.3 Unlike the previous configuration, the satellite option becomes satellites and each satellite will be determined by an identifier of your choice.\n# path\/to\/satellite.yaml version: 0.3 satellites: products: # this is the satellite key # ... The rest of the configuration is similar to the previous version.\nImporting external configuration files The major new feature of the version 0.3 is the ability to import external files in the Satellite configuration.\nThe import of files can be done at several levels in your config file:\nimports: # full configuration from another file - { resource: \u0026#39;path\/to\/another_config_file.yaml\u0026#39; } version: \u0026#39;0.3\u0026#39; satellites: imports: # configuration of a satellite - { resource: \u0026#39;path\/to\/satellite.yaml\u0026#39; } product: label: \u0026#39;Product\u0026#39; imports: # configuration of the adapter - { resource: \u0026#39;path\/to\/filesystem.yaml\u0026#39; } pipeline: imports: # configuration of the pipeline - { resource: \u0026#39;path\/to\/pipeline.yaml\u0026#39; } This way, you will be able to separate long and complex configurations into several smaller files.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/satellite\/"
						},

						{
							value: "Magento 2",
							label: "<p> What is it? Installation Usage Building an extractor Building a lookup Magento 2 is an e-commerce platform.\nWhat is it? This package includes classes to extract data from Magento, using a custom connector.\nInstallation composer require php-etl\/magento2-flow:\u0026#39;*\u0026#39; This package includes classes and code that you will be able to use in your custom connector.\nUsage Building an extractor The package includes the following extractor classes: CustomerExtractor, InvoiceExtractor, OrderExtractor, ProductExtractor.\nExtractor classes take 4 arguments:\nname description type default value logger the service that will log exceptions \\Psr\\Log\\LoggerInterface client client to choose depending on the Magento version. Available clients are: V2_1, V2_2, V2_3, V2_4 Client page size (Optional) maximum amount of entities to retrieve in a single payload int 100 filter groups (Optional) groups of filters to use when searching for entities array [] custom: extractor: use: \u0026#39;Kiboko\\Component\\Flow\\Magento2\\CustomerExtractor\u0026#39; services: Kiboko\\Component\\Flow\\Magento2\\CustomerExtractor: public: true arguments: - \u0026#39;@Monolog\\Logger\u0026#39; # Logger - \u0026#39;@Kiboko\\Magento\\V2_1\\Client\u0026#39; # Client - 500 # Page size - [] # Filter groups Kiboko\\Magento\\V2_1\\Client: factory: class: \u0026#39;Kiboko\\Magento\\V2_1\\Client\u0026#39; # Client method: \u0026#39;create\u0026#39; arguments: - \u0026#39;@Http\\Client\\Common\\PluginClient\u0026#39; Http\\Client\\Common\\PluginClient: arguments: - \u0026#39;@GuzzleHttp\\Client\u0026#39; - [ \u0026#39;@Http\\Client\\Common\\Plugin\\BaseUriPlugin\u0026#39;, \u0026#39;@Http\\Client\\Common\\Plugin\\AuthenticationPlugin\u0026#39; ] GuzzleHttp\\Client: ~ Http\\Client\\Common\\Plugin\\BaseUriPlugin: arguments: - \u0026#39;@GuzzleHttp\\Psr7\\Uri\u0026#39; Http\\Client\\Common\\Plugin\\AuthenticationPlugin: arguments: - \u0026#39;@Http\\Message\\Authentication\\Bearer\u0026#39; GuzzleHttp\\Psr7\\Uri: arguments: - \u0026#39;http:\/\/example-magento.com\u0026#39; # URL of the website Http\\Message\\Authentication\\Bearer: arguments: - \u0026#39;12345abcde\u0026#39; # Access token Monolog\\Logger: arguments: - \u0026#39;app\u0026#39; - [ \u0026#39;@Monolog\\Handler\\StreamHandler\u0026#39; ] Monolog\\Handler\\StreamHandler: arguments: - \u0026#39;var\/dev.log\u0026#39; # Path to the log file - 300 # Log level. 300 for Warning, 200 for Info... With filters Filters and filter groups can be specified. Filters in a group are chained with OR. Groups are chained with AND.\nIn this example we will search for customers that were updated after 1985 (@date_filter_group) and which have either the ID 17 or 46 (@id_filter_group).\n# ... Kiboko\\Component\\Flow\\Magento2\\CustomerExtractor: public: true arguments: - \u0026#39;@Monolog\\Logger\u0026#39; - \u0026#39;@Kiboko\\Magento\\V2_1\\Client\u0026#39; - 500 - [ \u0026#39;@date_filter_group\u0026#39;, \u0026#39;@id_filter_group\u0026#39; ] # updated_at \u0026gt;= 1985-10-26 11:25:00 AND (entity_id = 17 OR entity_id = 46) # ... date_filter_group: class: Kiboko\\Component\\Flow\\Magento2\\FilterGroup calls: - withFilter: [ \u0026#39;@last_execution\u0026#39; ] last_execution: class: Kiboko\\Component\\Flow\\Magento2\\Filter arguments: - \u0026#39;updated_at\u0026#39; - \u0026#39;gteq\u0026#39; - \u0026#39;1985-10-26 11:25:00\u0026#39; id_filter_group: class: Kiboko\\Component\\Flow\\Magento2\\FilterGroup calls: - withFilter: [ \u0026#39;@id_to_check\u0026#39;, \u0026#39;@other_id\u0026#39; ] id_to_check: class: Kiboko\\Component\\Flow\\Magento2\\Filter arguments: - \u0026#39;entity_id\u0026#39; - \u0026#39;eq\u0026#39; - \u0026#39;17\u0026#39; other_id: class: Kiboko\\Component\\Flow\\Magento2\\Filter arguments: - \u0026#39;entity_id\u0026#39; - \u0026#39;eq\u0026#39; - \u0026#39;46\u0026#39; # ... With long filter Filters are passed to the url. But the most popular web browsers will not work with URLs over 2000 characters, and would return a 414 (Request-URI Too Long). You can use the method withLongFilter to avoid this limitation and batch your request in multiple smaller requests.\nIn this example we will search for specific orders with a lot of elements in the request\u0026rsquo;s filter. We have 214 increment_id, and we use a withLongFilter with parameters:\n@order_increment_id references our order\u0026rsquo;s filter. offset, starts the request at the chosen index, by default we have 0. length, defines a batch length, by default we have 200. Here we have set an offset to 0 and a length to 150, it means we are starting the request from the first element and make multiple requests with 150 items max.\n# ... order_filter_group: class: Kiboko\\Component\\Flow\\Magento2\\FilterGroup calls: - withLongFilter: [ \u0026#39;@order_filter\u0026#39; ] order_filter: class: Kiboko\\Component\\Flow\\Magento2\\FilterGroup calls: - withLongFilter: [\u0026#39;@order_increment_id\u0026#39;, 0, 150] order_increment_id: class: Kiboko\\Component\\Flow\\Magento2\\Filter arguments: - \u0026#39;increment_id\u0026#39; - \u0026#39;in\u0026#39; - \u0026#39;000000526,4000000026,00000918,000001754,6000000123,4000000150,6000000185,000003798,6000000211,[..],5000000445\u0026#39; # ... Building a lookup There is a lookup class for Categories, and one for product Attributes.\nCategory Product attribute custom: transformer: use: \u0026#39;Kiboko\\Component\\Flow\\Magento2\\CategoryLookup\u0026#39; services: Kiboko\\Component\\Flow\\Magento2\\CategoryLookup: public: true arguments: - \u0026#39;@Monolog\\Logger\u0026#39; - \u0026#39;@Kiboko\\Magento\\V2_3\\Client\u0026#39; # Client to use depending on the Magento version. # Available clients are: # V2_1, V2_2, V2_3, V2_4 - \u0026#39;@Symfony\\Component\\Cache\\Psr16Cache\u0026#39; - \u0026#39;category.%s\u0026#39; - \u0026#39;@Acme\\Custom\\LookupMapper\u0026#39; # Your custom mapper class - \u0026#39;category_name\u0026#39; # Index of the category ID, in your line. Kiboko\\Magento\\V2_3\\Client: factory: class: \u0026#39;Kiboko\\Magento\\V2_3\\Client\u0026#39; # Client method: \u0026#39;create\u0026#39; arguments: - \u0026#39;@Http\\Client\\Common\\PluginClient\u0026#39; Http\\Client\\Common\\PluginClient: arguments: - \u0026#39;@GuzzleHttp\\Client\u0026#39; - [ \u0026#39;@Http\\Client\\Common\\Plugin\\BaseUriPlugin\u0026#39;, \u0026#39;@Http\\Client\\Common\\Plugin\\AuthenticationPlugin\u0026#39; ] GuzzleHttp\\Client: ~ Http\\Client\\Common\\Plugin\\BaseUriPlugin: arguments: - \u0026#39;@GuzzleHttp\\Psr7\\Uri\u0026#39; Http\\Client\\Common\\Plugin\\AuthenticationPlugin: arguments: - \u0026#39;@Http\\Message\\Authentication\\Bearer\u0026#39; GuzzleHttp\\Psr7\\Uri: arguments: - \u0026#39;http:\/\/example-magento.com\u0026#39; # URL of the website Http\\Message\\Authentication\\Bearer: arguments: - \u0026#39;12345abcde\u0026#39; # Access token Symfony\\Component\\Cache\\Psr16Cache: arguments: - \u0026#39;@Symfony\\Component\\Cache\\Adapter\\ApcuAdapter\u0026#39; Symfony\\Component\\Cache\\Adapter\\ApcuAdapter: ~ # Your custom mapper class Acme\\Custom\\LookupMapper: ~ Monolog\\Logger: arguments: - \u0026#39;app\u0026#39; - [ \u0026#39;@Monolog\\Handler\\StreamHandler\u0026#39; ] Monolog\\Handler\\StreamHandler: arguments: - \u0026#39;var\/dev.log\u0026#39; # Path to the log file - 300 # Log level. 300 for Warning, 200 for Info... custom: transformer: use: \u0026#39;Kiboko\\Component\\Flow\\Magento2\\Lookup\u0026#39; services: Kiboko\\Component\\Flow\\Magento2\\Lookup: public: true arguments: - \u0026#39;@Monolog\\Logger\u0026#39; - \u0026#39;@Kiboko\\Magento\\V2_3\\Client\u0026#39; # Client to use depending on the Magento version. # Available clients are: # V2_1, V2_2, V2_3, V2_4 - \u0026#39;@Symfony\\Component\\Cache\\Psr16Cache\u0026#39; - \u0026#39;collection.%s\u0026#39; # Cache key - \u0026#39;@Acme\\Custom\\LookupMapper\u0026#39; # Your custom mapper class - \u0026#39;Collection\u0026#39; # Index of the attribute ID, in your line. - \u0026#39;qv_collection\u0026#39; # Attribute code Kiboko\\Magento\\V2_3\\Client: factory: class: \u0026#39;Kiboko\\Magento\\V2_3\\Client\u0026#39; # Client method: \u0026#39;create\u0026#39; arguments: - \u0026#39;@Http\\Client\\Common\\PluginClient\u0026#39; Http\\Client\\Common\\PluginClient: arguments: - \u0026#39;@GuzzleHttp\\Client\u0026#39; - [ \u0026#39;@Http\\Client\\Common\\Plugin\\BaseUriPlugin\u0026#39;, \u0026#39;@Http\\Client\\Common\\Plugin\\AuthenticationPlugin\u0026#39; ] GuzzleHttp\\Client: ~ Http\\Client\\Common\\Plugin\\BaseUriPlugin: arguments: - \u0026#39;@GuzzleHttp\\Psr7\\Uri\u0026#39; Http\\Client\\Common\\Plugin\\AuthenticationPlugin: arguments: - \u0026#39;@Http\\Message\\Authentication\\Bearer\u0026#39; GuzzleHttp\\Psr7\\Uri: arguments: - \u0026#39;http:\/\/example-magento.com\u0026#39; # URL of the website Http\\Message\\Authentication\\Bearer: arguments: - \u0026#39;12345abcde\u0026#39; # Access token of the website Symfony\\Component\\Cache\\Psr16Cache: arguments: - \u0026#39;@Symfony\\Component\\Cache\\Adapter\\ApcuAdapter\u0026#39; Symfony\\Component\\Cache\\Adapter\\ApcuAdapter: ~ # Your custom mapper class Acme\\Custom\\LookupMapper: ~ Monolog\\Logger: arguments: - \u0026#39;app\u0026#39; - [ \u0026#39;@Monolog\\Handler\\StreamHandler\u0026#39; ] Monolog\\Handler\\StreamHandler: arguments: - \u0026#39;var\/dev.log\u0026#39; # Path to the log file - 300 # Log level. 300 for Warning, 200 for Info... Learn how to create your custom mapper class.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/magento-2\/"
						},

						{
							value: "Installation",
							label: "<p>Starting from here we will work inside a project directory we will name my_project_directory.\nmkdir my_project_directory \u0026amp;\u0026amp; cd my_project_directory Once the project dir is created and you have changed your current directory to it, the first task will be to initialize a composer project inside this directory and add all required dependencies.\ncomposer init In the auto-generated composer.json file, add the following lines at the end :\n{ \/\/ ... \u0026#34;config\u0026#34;: { \u0026#34;bin-dir\u0026#34;: \u0026#34;bin\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;post-install-cmd\u0026#34;: [ \u0026#34;Kiboko\\\\Component\\\\Satellite\\\\ComposerScripts::postInstall\u0026#34; ], \u0026#34;post-update-cmd\u0026#34;: [ \u0026#34;Kiboko\\\\Component\\\\Satellite\\\\ComposerScripts::postUpdate\u0026#34; ] } } Now, your environment is ready for the satellite compiler installation. The following command will install it.\ncomposer require php-etl\/satellite:\u0026#39;*\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/getting-started\/installation\/"
						},

						{
							value: "Expressions",
							label: "<p>Platform-specific expression functions Akeneo Expression functions We have developed some packages that provide expression functions to allow the use of more complex logic inside your satellites configuration.\nThese packages are based on the ExpressionLanguage Symfony component.\nSatellite Expression functions See the Base Expression functions documentation.\nArray Expression functions See the Array Expression functions documentation.\nString Expression functions See the String Expression functions documentation.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/expression-language\/"
						},

						{
							value: "Akeneo expression language functions",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it ? Installation Filter Provider Usage Functions reference Attribute data manipulation Filter by locale Filter by scope Take the first available value by scopes Combining results filter Excluding results filter Extracting a slice of the values list Extracting the beginning of the values list Extracting the end of the values list Extracting the values list, after an offset Extracting the first value from the list Extracting the last value from the list Dates management with dateTime and dateTimeZone Manage metrics with metricAmount, metricUnit and formatMetric Builder Provider Usage Functions reference What is it ? This library implements functions for manipulating Akeneo API data through the Symfony Expression Language.\nInstallation composer require php-etl\/akeneo-expression-language Filter Provider Usage To use Akeneo\u0026rsquo;s expression language functions, you must first add the expression_language key and put in the provider Kiboko\\Component\\ExpressionLanguage\\Akeneo\\AkeneoFilterProvider.\nThen, in the fields that can use expression languages, you can use any functions provided by the Akeneo provider.\nYAML PHP - fastmap: expression_language: - \u0026#39;Kiboko\\Component\\ExpressionLanguage\\Akeneo\\AkeneoFilterProvider\u0026#39; map: - field: \u0026#39;[title]\u0026#39; expression: \u0026#39;filter(input[\u0026#34;title\u0026#34;], scope(\u0026#34;print\u0026#34;, \u0026#34;mobile\u0026#34;, \u0026#34;web\u0026#34;), first())\u0026#39; \u0026lt;?php use Symfony\\Component\\ExpressionLanguage\\ExpressionLanguage; use Kiboko\\Component\\ExpressionLanguage\\Akeneo\\AkeneoFilterProvider; $input = [ [ \u0026#39;locale\u0026#39; =\u0026gt; \u0026#39;en_US\u0026#39;, \u0026#39;scope\u0026#39; =\u0026gt; \u0026#39;mobile\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; \u0026#39;Lorem ipsum dolor sit amet\u0026#39;, ], [ \u0026#39;locale\u0026#39; =\u0026gt; \u0026#39;fr_CA\u0026#39;, \u0026#39;scope\u0026#39; =\u0026gt; \u0026#39;web\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; \u0026#39;Lorem ipsum dolor sit amet\u0026#39;, ], [ \u0026#39;locale\u0026#39; =\u0026gt; \u0026#39;fr_CA\u0026#39;, \u0026#39;scope\u0026#39; =\u0026gt; \u0026#39;marketplace\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; \u0026#39;Lorem ipsum dolor sit amet\u0026#39;, ], [ \u0026#39;locale\u0026#39; =\u0026gt; \u0026#39;fr_FR\u0026#39;, \u0026#39;scope\u0026#39; =\u0026gt; \u0026#39;print\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; \u0026#39;Lorem ipsum dolor sit amet\u0026#39;, ], [ \u0026#39;locale\u0026#39; =\u0026gt; \u0026#39;en_GB\u0026#39;, \u0026#39;scope\u0026#39; =\u0026gt; \u0026#39;mobile\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; \u0026#39;Lorem ipsum dolor sit amet\u0026#39;, ], ]; $expression = \u0026#39;filter(input, scope(\u0026#34;print\u0026#34;, \u0026#34;mobile\u0026#34;, \u0026#34;web\u0026#34;), first())\u0026#39;; $interpreter = new ExpressionLanguage(null, [new AkeneoFilterProvider()]); $interpreter-\u0026gt;evaluate($expression, [\u0026#39;input\u0026#39; =\u0026gt; $input]); Functions reference Attribute data manipulation Akeneo has a specific data format that would make cumbersome the data mapping if there were no dedicated tools. In this matter the Expression Language functions for Akeneo gives you more control over what you wish to synchronize.\nThere are two functions that have to be used in order to filter or extract data from your Akeneo attributes:\nfilter ( data , ...filter ): filter the available values for an attribute attribute ( data , ...filter ): extract the most accurate value Those functions needs som companions in order to be useful. Those companions will help you to apply filtering depending on your business logic.\nFilter by locale locale ( string ...locale )\nThis filter will extract only the locales that match the provided locale codes, with no reordering.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], locale(\u0026quot;fr_CA\u0026quot;, \u0026quot;fr_FR\u0026quot;))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, }, ] Filter by scope scope ( string ...scope )\nThis filter will extract only the scopes that match the provided scope codes, with no reordering.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], scope(\u0026quot;web\u0026quot;, \u0026quot;print\u0026quot;))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, }, ] Take the first available value by scopes coalesce ( string ...scope )\nThis filter will extract the first value tat matches a scope in the provided scope codes.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], coalesce(\u0026quot;web\u0026quot;, \u0026quot;print\u0026quot;))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, }, ] Combining results filter anyOf ( ...filters )\nThis filter will combine several filters into one result, applying an OR\nto every specified filter. It will result in a list where at least one filter is true.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], anyOf(scope(\u0026quot;web\u0026quot;), locale(\u0026quot;fr_FR\u0026quot;)))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, }, ] Excluding results filter allOf ( ...filters )\nThis filter will combine several filters into one result, applying an AND\nto every specified filter. It will result in a list where all filters are true.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], allOf(scope(\u0026quot;web\u0026quot;), locale(\u0026quot;fr_FR\u0026quot;)))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Extracting a slice of the values list slice ( int offset , int length )\nThis filter will extract length values, starting at offset.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], slice(1, 2))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Extracting the beginning of the values list head ( int length )\nThis filter will extract length values, starting at the beginning.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], head(2))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Extracting the end of the values list tail ( int length )\nThis filter will extract length values, starting at the end.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], tail(2))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Extracting the values list, after an offset offset ( int offset )\nThis filter will extract all the values after the offset position.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], offset(1))\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Extracting the first value from the list first ( )\nThis filter will extract the first value of the list.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], first())\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Extracting the last value from the list last ( )\nThis filter will extract the last value of the list.\nfilter(input[\u0026quot;data\u0026quot;][\u0026quot;description\u0026quot;], first())\nFilter Result Data Source [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] [ { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;en_US\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_CA\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; }, { \u0026#34;locale\u0026#34;: \u0026#34;fr_FR\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;print\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34; } ] Dates management with dateTime and dateTimeZone In order to generate date objects, two functions has been created:\ndateTime ( string date, [ string format ] )\ndateTimeZone ( string date, string timezone [ string format ] )\nThe results will be \\DateTimeImmutable PHP objects.\nManage metrics with metricAmount, metricUnit and formatMetric metricAmount(string $value, int $decimalRound = 4)\nThis function will extract the decimal part of a metric attribute\u0026rsquo;s value\nmetricUnit(string $value)\nThis function will extract the unit part of a metric attribute\u0026rsquo;s value\nformatMetric(array $attribut, string $locale)\nThis function will format the metric according to the specified locale\nBuilder Provider The Akeneo API expects you to have certain types of format for your attributes. The functions provided by the AkeneoBuilderProvider allow you to create the expected formats easily.\nUsage To use the Akeneo\u0026rsquo;s Builder expression language, you must first add the expression_language key and put in the provider Kiboko\\Component\\ExpressionLanguage\\Akeneo\\AkeneoBuilderProvider.\nThen, in the fields that can use expression languages, you can use any functions provided by the Akeneo Builder provider.\nYAML - fastmap: expression_language: - \u0026#39;Kiboko\\Component\\ExpressionLanguage\\Akeneo\\AkeneoBuilderProvider\u0026#39; map: - field: \u0026#39;[title]\u0026#39; expression: \u0026#39;withValue(input[\u0026#34;title\u0026#34;])\u0026#39; Functions reference Name Description Example build(string \u0026hellip;values) Enables several values to be grouped together in a single ordered array corresponding to the format that the API expects. build(input[\u0026ldquo;values\u0026rdquo;]) withValue(string value, string locale, string scope) Creates the expected format for attributes of type single-line text, multi-line text, boolean, date, number, measurement. withValue(input[\u0026ldquo;variant_name\u0026rdquo;], \u0026ldquo;fr_FR\u0026rdquo;, \u0026ldquo;ecommerce\u0026rdquo;) withSimpleOption(string code, string attribute, string labels, string locale = \u0026rsquo;null\u0026rsquo;, string scope = \u0026rsquo;null\u0027) Creates the expected format for single-option attributes. build(withSimpleOption(\u0026ldquo;PHY\u0026rdquo;,\u0026ldquo;kind\u0026rdquo;, {\u0026ldquo;fr_FR\u0026rdquo;: \u0026ldquo;PHY\u0026rdquo;})) withMultipleOption(string codes, string attribute, string labels, string locale, string scope) Creates the expected format for multiple-option attributes. withMultipleOption(input[\u0026ldquo;collection\u0026rdquo;], \u0026ldquo;collection\u0026rdquo;, {\u0026ldquo;fr_FR\u0026rdquo;: \u0026ldquo;My collection\u0026rdquo;}, \u0026ldquo;fr_FR\u0026rdquo;, \u0026ldquo;ecommerce\u0026rdquo;) withReferenceEntityValue(string value, string locale = \u0026rsquo;null\u0026rsquo;, string channel = \u0026rsquo;null\u0027) Creates the expected format for reference entity record attributes of type single-line text, multi-line text, boolean, date, number, measurement. withReferenceEntityValue(input[\u0026ldquo;label\u0026rdquo;], \u0026ldquo;fr_FR\u0026rdquo;) withReferenceEntitySimpleOption(string value, string locale = \u0026rsquo;null\u0026rsquo;, string channel = \u0026rsquo;null\u0027) Creates the expected format for simple-select reference entity record attributes. withReferenceEntitySimpleOption(input[\u0026ldquo;associated_crops_code\u0026rdquo;], \u0026ldquo;fr_FR\u0026rdquo;) </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/akeneo\/expression-language\/"
						},

						{
							value: "CSV",
							label: "<p> What is it ? Installation Usage Building an extractor Building a loader Additional options Advanced Usage Splitting into several files See more CSV, Comma-Separated Values, is a spreadsheet-like computer file with values separated by commas.\nWhat is it ? The CSV plugin aims at integrating the CSV reader and writer into the Pipeline stack.\nInstallation composer require php-etl\/csv-plugin:\u0026#39;*\u0026#39; Usage Building an extractor To build an extractor, you need to specify the path of your file.\ncsv: extractor: file_path: \u0026#39;input.csv\u0026#39; Building a loader To build a loader, you need to specify the path of your file.\ncsv: loader: file_path: \u0026#39;output.csv\u0026#39; Additional options To build extractors or loaders, additional options exist and can be used :\ndelimiter : sets the field separator enclosure : sets the text enclosure character escape : sets the escape character safe_mode : enable safe mode in the Pipeline columns : specify the name of the columns to retrieve or write csv: loader: file_path: \u0026#39;output.csv\u0026#39; delimiter: \u0026#39;\/\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; escape: \u0026#39;\\\\\u0026#39; safe_mode: true columns: - firstname - lastname Advanced Usage Splitting into several files To limit the number of lines to be written to your csv file, you can specify the max_lines option.\ncsv: expression_language: - \u0026#39;Kiboko\\Component\\StringExpressionLanguage\\StringExpressionLanguageProvider\u0026#39; loader: # ... max_lines: 20 file_path: \u0026#39;@=env(\u0026#34;OUTPUT_DIRECTORY\u0026#34;)~format(\u0026#34;output_%06d.csv\u0026#34;,index)\u0026#39; For the dynamic filename to work, you must install php-etl\/string-expression-language:\ncomposer require php-etl\/string-expression-language Warning : this option is only available for loaders\nUsing a nonstandard format In some cases, it is possible to generate a csv file that does not correspond to the standard format (for example by removing the enclosures). For this we have added the nonstandard option which is a boolean.\ncsv: loader: # ... nonstandard: true Notice : The nonstandard option cannot be used with the enclosure and escape options.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/csv\/"
						},

						{
							value: "Pipeline",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it for? Installation Basic Usage Advanced Usage Using expressions Using services Adding logger Adding rejection Adding state Setting environment variables A pipeline is a series of processes, also called steps, that filter or transform data. The first process takes raw input data, uses it and then sends the results to the second process, and so on, ending with the final result produced by the last process in progress.\nThe different steps of our pipeline are extract, transform or load but the transformation step isn\u0026rsquo;t mandatory.\nTip : It\u0026rsquo;s possible to use multiple transformation steps in a pipeline.\nWhat is it for? This package allows you to create a microservice that will be operating a data pipeline.\nBasic usage To define your pipeline, you need to specify which steps will make up the pipeline using the steps option. Each step contains the configuration of a plugin. For more details, go to the documentation page of the plugin of your choice.\nYou must also set a code of your choosing, which will help identify the pipeline. This pipeline code should be unique within the satellite.\nYAML PHP pipeline: code: \u0026#39;my-example-pipeline\u0026#39; steps: - csv: extractor: file_path: path\/to\/file\/input.csv delimiter: \u0026#39;;\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; escape: \u0026#39;\\\\\u0026#39; - csv: loader: file_path: path\/to\/file\/output.csv delimiter: \u0026#39;,\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; escape: \u0026#39;\\\\\u0026#39; \u0026lt;?php use Kiboko\\Component\\Pipeline\\PipelineRunner; use Kiboko\\Component\\Pipeline\\Pipeline; use Kiboko\\Component\\Flow\\Csv\\Safe\\Extractor; use Kiboko\\Component\\Flow\\Csv\\Safe\\Loader; \/** @var Psr\\Log\\LoggerInterface $logger *\/ $runner = new PipelineRunner(); $pipeline = (new Pipeline($runner)) -\u0026gt;extract((new Extractor(\u0026#39;path\/to\/file\/input.csv\u0026#39;))-\u0026gt;setLogger($logger)) -\u0026gt;load(new Loader(\u0026#39;path\/to\/file\/output.csv\u0026#39;, delimiter: \u0026#39;,\u0026#39;)) -\u0026gt;run(); Advanced usage Using expressions It\u0026rsquo;s possible to use expressions in your pipeline using the expression_language option. To use these expressions, you need to use our customised Providers which provide the different expressions. For more information, please visit the detailed documentation of the language expressions.\npipeline: expression_language: - \u0026#39;Kiboko\\Component\\Satellite\\ExpressionLanguage\\Provider\u0026#39; Using services You can use services in your pipeline in the same way as in a traditional Symfony application.\nFor more details, go to the detailed services documentation.\npipeline: services: App\\Service\\Bar: arguments: - \u0026#39;my-file.csv\u0026#39; Adding logger It\u0026rsquo;s possible to add a logger at each step of the pipeline.\nFor more details, go to the detailed logger documentation.\nsatellite: # ... pipeline: code: \u0026#39;my-example-pipeline\u0026#39; steps: - akeneo: # ... logger: channel: pipeline destinations: - elasticsearch: level: warning hosts: - http:\/\/user:password@elasticsearch.example.com:9200 Adding rejection It\u0026rsquo;s possible to add a rejection at each step of the pipeline.\nFor more details, go to the detailed rejection documentation\nsatellite: # ... pipeline: code: \u0026#39;my-example-pipeline\u0026#39; steps: - akeneo: # ... rejection: destinations: - rabbitmq: host: rabbitmq.example.com vhost: \/ topic: foo.rejects Adding state It\u0026rsquo;s possible to add a state at each step of the pipeline.\nFor more details, go to the detailed state documentation\nsatellite: # ... pipeline: code: \u0026#39;my-example-pipeline\u0026#39; steps: - akeneo: # ... state: destinations: - rabbitmq: host: rabbitmq.example.com vhost: \/ topic: foo.rejects Setting environment variables It\u0026rsquo;s possible to set environment variables in a .env file, located in your working directory, to re-use those variables in the declaration of your pipeline.\nExample of a .env file:\nMY_SERVICE_API_KEY=abc123 SOME_SECRET_KEY=123456789 Then use the variables like this in the configuration:\n# ... pipeline: code: \u0026#39;my-example-pipeline\u0026#39; steps: - akeneo: # ... client: client_id: \u0026#39;@=env(\u0026#34;MY_SERVICE_API_KEY\u0026#34;)\u0026#39; secret: \u0026#39;@=env(\u0026#34;SOME_SECRET_KEY\u0026#34;)\u0026#39; The .env file must be located in the working directory (next to the configuration file of your pipeline), as it will be symlinked inside the resulting build files.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/satellite\/pipeline\/"
						},

						{
							value: "Writing Configuration",
							label: "<p>Next, we will guide you through the configuration process and explain how to use our different plugins.\nThe first thing to do is creating a configuration file which we will call satellite.yaml.\nTo avoid keeping all our files at the root of the project, we will create satellite.yaml inside a src\/ folder.\nIn a terminal, enter the following command:\nmkdir src \u0026amp;\u0026amp; touch src\/satellite.yaml Then add this configuration to your YAML file:\nversion: \u0026#39;0.3\u0026#39; satellites: csv_to_json: label: \u0026#39;CSV to JSON\u0026#39; filesystem: path: build pipeline: steps: - csv: extractor: file_path: \u0026#39;data\/products.csv\u0026#39; - json: loader: file_path: \u0026#39;output.json\u0026#39; In our case, we use csv as an extractor and json as a loader, so we have to add the corresponding plugins to our project:\ncomposer require php-etl\/csv-plugin:\u0026#39;*\u0026#39; php-etl\/json-plugin:\u0026#39;*\u0026#39; Composer will install a version of the plugin that is compatible with the php-etl\/satellite package you have previously installed. Find the different versions of our plugins here.\nIn a configuration file, paths start at the folder specified under filesystem.path. Here for example, the result will be src\/build\/output.csv.\nFor more information on how to write your configuration, please read satellites.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/getting-started\/writing-configuration\/"
						},

						{
							value: "Workflow",
							label: "<p> What is it ? Installation Basic usage Advanced usage Using expression Using services What is it ? This package allows you to create a micro-service that will be orchestrating more than one data pipeline.\nInstallation composer require php-etl\/workflow:\u0026#39;*\u0026#39; Basic usage To define your workflow, you need to specify the jobs you need, that is to say your different pipelines or actions.\nEach job must be identified by a code. If you forget it, you will be reminded to add it.\nworkflow: jobs: job-1: # this is your job code pipeline: # ... job-2: pipeline: # ... job-3: action: # ... You can declare your codes in another way, but which we find less legible. We advise you to use the first method, but it\u0026rsquo;s good to know the 2 solutions.\nworkflow: jobs: - code: \u0026#39;job-1\u0026#39; # this is your job code pipeline: # ... - code: \u0026#39;job-2\u0026#39; pipeline: # ... - code: \u0026#39;job-3\u0026#39; action: # ... The name option allows you to name your job.\nworkflow: jobs: job-1: name: \u0026#39;First Pipeline\u0026#39; pipeline: # the pipeline configuration # ... Advanced usage Using expressions It\u0026rsquo;s possible to use expressions in your pipeline using the expression_language option. To use these expressions, you need to use our customised Providers which provide the different expressions. For more information, please visit the detailed documentation of the language expressions.\npipeline: expression_language: - \u0026#39;Kiboko\\Component\\Satellite\\ExpressionLanguage\\Provider\u0026#39; Using services You can use services in your pipeline in the same way as in a traditional Symfony application.\nFor more details, go to the detailed services documentation.\npipeline: services: App\\Service\\Bar: arguments: - \u0026#39;my-file.csv\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/satellite\/workflow\/"
						},

						{
							value: "Logging",
							label: "<p> What is it for? Installation Usage Setting your channel Setting one or more destinations Using a Stream Using ElasticSearch Using Syslog Using GELF Using Logstash The different levels of logs in PHP A log is a type of file that stores a history of messages.\nWhat is it for? In some cases you may need to identify why your Pipeline is failing, so we have set up a logger system that you can use in different steps of your pipeline.\nInstallation This plugin is already integrated into the Satellite package, so you won\u0026rsquo;t need to require it with composer.\nUsage Setting your channel First, you need to specify the name of your channel in which your logs will be written.\n- example_step: logger: channel: pipeline Setting one or more destinations Next, you need to define the destination(s) for your logs. You can choose between several logging systems: ElasticSearch, Logstash, Gelf, Syslog and Stream.\nUsing a Stream A log stream is an application-specific collection of data that is used as a log. The data is written to and read from the log stream by one or more instances of the associated application.\nTo establish a connection to a stream, you need to define a path and the minimum logging level at which this handler will be triggered with the level option.\n- example_step: logger: # ... destinations: - stream: path: var\/example.log level: warning Using ElasticSearch ElasticSearch is a search and analysis engine.\nThe first thing to set is the minimum logging level at which this handler will be triggered using the the level option.\nNote: if you need to install a local ElasticStack environment, check the Manual installation documentation.\nNext, you need to set the various hosts for your ElasticSearch application.\n- example_step: logger: # ... destinations: - elasticsearch: level: warning hosts: - http:\/\/user:password@elasticsearch.example.com:9200 Using Syslog Syslog, System Logging Protocol, is a standard protocol used to send system log files or event messages to a dedicated server called syslog server.\nUsing GELF The Graylog Extended Log Format (GELF) is a unique and convenient log format created to address all the shortcomings of the traditional Syslog. This feature allows you to collect structured events from anywhere, then compress and fragment them in a snap.\nThe first thing to do is to set the minimum logging level at which this handler will be triggered using the level option.\nNext, you need to set the protocol you want to use: TCP or AMQP.\nTCP AMQP - example_step: logger: # ... destinations: - gelf: level: warning tcp: host: gelf.example.com port: 100 - example_step: logger: # ... destinations: - gelf: level: warning amqp: queue: my_queue_name host: example.com port: 100 login: foo password: password Using Logstash Logstash is a software tool for collecting, analysing and storing logs.\nWhen setting up your connection to Logstash, you should first set the name of your application using the application_name option and the minimum logging level at which this handler will be with the level option.\nNext, you need to set the protocol you want to use: TCP or AMQP.\nTCP AMQP - example_step: logger: # ... destinations: - logstash: application_name: my_log_system level: warning tcp: host: logstash.example.com port: 100 - example_step: logger: # ... destinations: - logstash: application_name: my_log_system level: warning amqp: queue: my_queue_name host: example.com port: 100 login: foo password: password The different levels of logs in PHP debug, info, notice, warning, error, critical, alert, emergency\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/logger\/"
						},

						{
							value: "Custom connector",
							label: "<p> What is it ? Installation Usage Building an extractor Building a transformer Building a loader Usage examples Example of an extractor Example of a transformer Example of a loader Definition The custom plugin allows you to use your own source code in your pipelines, allowing you to connect tools that are not supported by the standard distribution.\nInstallation This plugin is already integrated into the Satellite package, so you cant require it with the composer.\nUsage Unlike other plugins, the configuration is the same whether it is an extractor, a transformer or a loader.\nBuilding an extractor In the example given, we explain how to configure a custom extractor with the Bar class located in the App\\Class namespace.\nHere\u0026rsquo;s a more detailed explanation:\ncustom: extractor: use: \u0026#39;App\\Class\\Bar\u0026#39; # This line specifies the extractor class you want to use. services: App\\Class\\Bar: ~ # Here, we declare the service associated with the Bar class with the syntax App\\Class\\Bar: ~. This simply indicates that we want to use the default parameters for this service. For more details about service configurations, please visit the declaring-services documentation.\nBuilding a transformer In the example given, we explain how to configure a custom extractor with the Bar class located in the App\\Class namespace.\nHere\u0026rsquo;s a more detailed explanation:\ncustom: transformer: use: \u0026#39;App\\Class\\Bar\u0026#39; # This line specifies the extractor class you want to use. services: App\\Class\\Bar: # Here, we declare the service associated with the Bar class. factory: # This section indicates that the service must be created by calling the extract method of the App\\Class\\Bar class. class: App\\Class\\Bar method: extract arguments: # The arguments to be passed to the extract method. In this example, the @foo symbol indicates that the foo service should be injected as an argument. Make sure that the foo service is configured correctly elsewhere in your pipeline. - \u0026#39;@foo\u0026#39; foo: ~ For more details about service configurations, please visit the declaring-services documentation.\nBuilding a loader In the example given, we explain how to configure a custom extractor with the Bar class located in the App\\Class namespace.\nHere\u0026rsquo;s a more detailed explanation:\ncustom: loader: use: \u0026#39;App\\Class\\Bar\u0026#39; # This line specifies the extractor class you want to use. services: App\\Class\\Bar: # Here, we declare the service associated with the Bar class. calls: # This section indicates that specific method calls must be made to the service instance. - withUsername: [ \u0026#39;admin\u0026#39; ] # This means that a method call named withUsername must be made to the instance of the Bar class, with the username \u0026#34;admin\u0026#34; passed as an argument. For more details about service configurations, please visit the declaring-services documentation.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/custom\/"
						},

						{
							value: "HTTP Hook",
							label: "<p> What is it ? Installation Basic usage Advanced usage Adding JWT Authorization Adding Basic HTTP Authorization What is it ? This package allows you to create an API that will serve a single endpoint.\nThe goal is to be able to send data to this endpoint, to process it in a series of steps.\nBasic usage Your HTTP Hook will serve the route set in the option path:\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;Example of a hook\u0026#39; filesystem: path: build composer: require: - \u0026#34;middlewares\/uuid:dev-master\u0026#34; - \u0026#34;middlewares\/base-path:dev-master\u0026#34; - \u0026#34;middlewares\/request-handler:dev-master\u0026#34; - \u0026#34;middlewares\/fast-route:dev-master\u0026#34; - \u0026#34;laminas\/laminas-diactoros\u0026#34; - \u0026#34;laminas\/laminas-httphandlerrunner\u0026#34; - \u0026#34;nyholm\/psr7-server\u0026#34; - \u0026#34;nyholm\/psr7\u0026#34; - \u0026#34;php-etl\/pipeline\u0026#34; - \u0026#34;php-etl\/satellite\u0026#34; - \u0026#34;php-etl\/api-runtime\u0026#34; - \u0026#34;php-etl\/mapping-contracts\u0026#34; http_hook: name: \u0026#39;My HTTP Hook\u0026#39; # Optional path: \/my-hook expression: \u0026#39;input\u0026#39; pipeline: steps: - fastmap: map: - field: \u0026#39;[sku]\u0026#39; copy: \u0026#39;[product_name]\u0026#39; - field: \u0026#39;[id]\u0026#39; copy: \u0026#39;[product_code]\u0026#39; - csv: loader: file_path: \u0026#39;output.csv\u0026#39; After building the satellite, start a server in the path build\/:\nbin\/satellite run:hook build\/ You can then send POST requests containing the data to process to http:\/\/localhost:8000\/my-hook\n# input: [ { product_name: \u0026#39;test_1\u0026#39;, product_code: 861 }, { product_name: \u0026#39;test_2\u0026#39;, product_code: 862 } ] # response: {\u0026#34;message\u0026#34;:{\u0026#34;accept\u0026#34;:4,\u0026#34;reject\u0026#34;:0,\u0026#34;error\u0026#34;:0},\u0026#34;server\u0026#34;:\u0026#34;my-computer.local\u0026#34;} # output.csv: sku;id test_1;861 test_2;862 Advanced usage Adding JSON Web Token (JWT) Authorization # ... composer: require: - \u0026#34;tuupola\/slim-jwt-auth\u0026#34; # ... http_hook: authorization: jwt: secret: \u0026#39;mysecret\u0026#39; With this config, each requests will need the header Authorization:\nheader value Authorization Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6Ik[\u0026hellip;] The string after \u0026ldquo;Bearer\u0026rdquo; is the token, generated from the secret phrase. This site can be used to generate a token from your own secret: https:\/\/jwt.io\nAdding Basic HTTP Authorization # ... composer: require: - \u0026#34;tuupola\/slim-basic-auth\u0026#34; # ... http_hook: authorization: basic: - user: john password: mypassword - user: bill password: otherpassword The basic node is an array, and can contain multiple user\/password pairs.\nWith this configuration, each requests will need the header Authorization:\nheader value Authorization Basic am9objpteXBhc3N3b3Jk The string after \u0026ldquo;Basic\u0026rdquo; is the combination user:password encoded in Base64.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/satellite\/http-hook\/"
						},

						{
							value: "Action",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it for? Installation Basic Usage Advanced Usage Using expressions Adding logger Adding state An action is a process that enables a task to be carried out before, during or at the end of the execution of a workflow. For example, an action can be used to retrieve or upload files to an SFTP server.\nWhat is it for? This package provides a process capable of executing actions.\nInstallation composer require php-etl\/action:\u0026#39;*\u0026#39; Basic usage At present, actions can only be used within a workflow. It is therefore not currently possible to launch an action on its own.\nworkflow: jobs: job-1: action: # ... We\u0026rsquo;ve made sure that you can use your own actions.\nYou need to implement the Kiboko\\Contract\\Action\\Interface and in the execute method, you simply write your script.\n\u0026lt;?php namespace App; final readonly class MyCustomAction implements ActionInterface { public function execute(): void { \/\/ write your script here } } Once you\u0026rsquo;ve written your action, you need to use it in your Satellite using the custom action plugin like this.\nworkflow: jobs: job-1: action: custom: use: \u0026#39;App\\MyCustomAction\u0026#39; services: App\\MyCustomAction: ~ To find out more about how to use services, visit declaring services.\nAdvanced usage Using expressions It\u0026rsquo;s possible to use expressions in your pipeline using the expression_language option. To use these expressions, you need to use our customised Providers which provide the different expressions. For more information, please visit the detailed documentation of the language expressions.\naction: expression_language: - \u0026#39;Kiboko\\Component\\Satellite\\ExpressionLanguage\\Provider\u0026#39; Adding logger It\u0026rsquo;s possible to add a logger at each action of a workflow.\nFor more details, go to the detailed logger documentation.\nsatellite: # ... workflow: jobs: job-1: action: # ... logger: channel: pipeline destinations: - elasticsearch: level: warning hosts: - http:\/\/user:password@elasticsearch.example.com:9200 Adding state It\u0026rsquo;s possible to add a state at each action of a workflow.\nFor more details, go to the detailed state documentation\nsatellite: # ... workflow: jobs: job-1: action: # ... state: destinations: - rabbitmq: host: rabbitmq.example.com vhost: \/ topic: foo.rejects As you can see, actions are only able to manage the logs and states of their processes, but cannot deal with rejects that are contrary to pipelines.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/satellite\/action\/"
						},

						{
							value: "Compilation",
							label: "<p>After checking and verifying that the configuration of your pipelines are correct, you will be able to compile your configuration.\nIn a terminal, write the following command :\nphp bin\/satellite build src\/satellite.yaml In our case, the pipeline will be compiled under src\/build\/, the directory specified in filesystem.path of the configuration.\nNotice: You will need to run this command every time you change your configuration files.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/getting-started\/compilation\/"
						},

						{
							value: "Rejection",
							label: "<p> What is it for? Installation Usage With RabbitMQ What is it for? The rejection feature allows you to manage the rejections that may occur in your project.\nInstallation This plugin is already integrated into the Satellite package, so you can\u0026rsquo;t require it with composer.\nUsage When you configure your pipeline, you can add the configuration of this feature to your step configuration.\nFirst, you must use the rejection option.\n- example_step: foo: bar rejection: # ... With RabbitMQ This feature supports sending to RabbitMQ instances. For this feature to work you will need to install bunny\/bunny:\ncomposer require bunny\/bunny Basic configuration To enable a connection to your RabbitMQ application, you need at least 4 options which are host, vhost, topic and port.\nhost: the name of your host name vhost: the virtual host of your RabbitMQ instance topic: the name of the queue to which the rejects will be sent port: the port that your RabbitMQ application uses - example_step: # ... rejection: destinations: - rabbitmq: host: rabbitmq.example.com vhost: \/ topic: foo.rejects port: 5672 Additional options This feature additionally takes some options that can be used when configuring to your instance.\nuser: the username of your user password: the password of your user exchange: the name of the exchange to be used - example_step: # ... rejection: destinations: - rabbitmq: host: rabbitmq.example.com vhost: \/ topic: foo.rejects port: 5672 user: \u0026#39;guest\u0026#39; password: \u0026#39;guest\u0026#39; exchange: \u0026#39;amq.direct\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/rejection\/"
						},

						{
							value: "Fast Map",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it ? Installation Usage Building an ArrayMapper Building a ListMapper Building a CollectionMapper Building an ObjectMapper Building a ConditionalMapper A mapping is an operation that associates each element of a source of data into a new format of the same data. By this operation, it is possible to transform the way the data is represented.\nWhat is it ? The FastMap plugin aims at integrating mappers into the Pipeline stack.\nFastMap Plugin consists of two components, each with a different purpose.\nThe php-etl\/fast-map component This component is in charge of representing the Abstract Mapping Tree, and transforming it into compiled PHP code. This compiled PHP code is the actual code that will do the mapping, in an optimized way.\nAbstract Mapping Tree The abstract mapping tree is a representation of the mapping to apply to your data, in order to transform its representation. It is an internal representation build for a computer to understand how it will have to change the data representation during the mapping operation.\nThe php-etl\/fast-map-config component This component allows you to configure your mapper according to the type of data you want to input.\nIf you need to config your mappers, we advise you to use the yml config which will generate a php code usable by the fast-map-config. This code will then be converted into a machine code that can be used by the fast map package.\nInstallation composer require php-etl\/fast-map-plugin:\u0026#39;*\u0026#39; Usage Building an ArrayMapper To write a mapping to an array, you must use the \u0060map option.\nfastmap: append: true # Optional. Merges this step\u0026#39;s output into the previous step\u0026#39;s result. map: # ... Next, you need to specify the field you are going to map to and assign a value to it.\nThe field option is based on the PropertyAccess component of Symfony. You must therefore respect this [field_name] naming format.\nTo assign a value to your field, you can choose between several options :\nSimple options copy : This option also uses the PropertyAccess component of Symfony and allows you to retrieve a value from an array and copy it. expression : This expression uses the Expressionlanguage component of Symfony component and allows you to write your own expressions. constant : This option allows you to write directly the value of your field fastmap: map: - field: \u0026#39;[sku]\u0026#39; copy: \u0026#39;[sku]\u0026#39; - field: \u0026#39;[title]\u0026#39; expression: \u0026#39;input[\u0026#34;sku\u0026#34;] ~\u0026#34; | \u0026#34;~ input[\u0026#34;name\u0026#34;]\u0026#39; - field: \u0026#39;[staticValue]\u0026#39; constant: \u0026#39;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur mollis efficitur justo, id facilisis elit venenatis et.\u0026#39; # ... Advanced options map : see the configuration list : see the configuration collection : see the configuration object : see the configuration fastmap: map: - field: \u0026#39;[foo]\u0026#39; expression: \u0026#39;input\u0026#39; map: - field: \u0026#39;[bar]\u0026#39; copy: \u0026#39;[bar]\u0026#39; - field: \u0026#39;[foo]\u0026#39; expression: \u0026#39;input\u0026#39; list: - field: \u0026#39;[bar]\u0026#39; copy: \u0026#39;[bar]\u0026#39; - field: \u0026#39;[descriptions]\u0026#39; class: \u0026#39;Pipeline\\Usage\u0026#39; expression: \u0026#39;input[\u0026#34;foo\u0026#34;]\u0026#39; object: - field: \u0026#39;usage\u0026#39; expression: \u0026#39;\u0026#34;Usage: \u0026#34; ~ input[\u0026#34;usage\u0026#34;]\u0026#39; - field: \u0026#39;warning\u0026#39; copy: \u0026#39;[warning]\u0026#39; - field: \u0026#39;notice\u0026#39; copy: \u0026#39;[notice]\u0026#39; - field: \u0026#39;[messages]\u0026#39; class: \u0026#39;Foo\\DTO\\Messages\u0026#39; expression: \u0026#39;input\u0026#39; collection: - field: \u0026#39;usage\u0026#39; expression: \u0026#39;\u0026#34;Usage: \u0026#34; ~ input[\u0026#34;usage\u0026#34;]\u0026#39; - field: \u0026#39;warning\u0026#39; copy: \u0026#39;[warning]\u0026#39; - field: \u0026#39;notice\u0026#39; copy: \u0026#39;[notice]\u0026#39; Building a ListMapper To write a mapping to a list, you must use the list option, which will always be accompanied by the expression option.\nexpression : allows you to write an expression which will be used in the mapping. fastmap: expression: \u0026#39;input\u0026#39; list: - field: \u0026#39;[bar]\u0026#39; copy: \u0026#39;[bar]\u0026#39; Building a CollectionMapper To write a mapping to a collection of objects, you must use the collection option, which will always be accompanied by the class and expression options.\nclass : determines the class to use in the mapping. expression : allows you to write an expression which will be used in the mapping. fastmap: class: \u0026#39;Foo\\DTO\\Messages\u0026#39; expression: \u0026#39;input\u0026#39; collection: - field: \u0026#39;usage\u0026#39; expression: \u0026#39;\u0026#34;Usage: \u0026#34; ~ input[\u0026#34;usage\u0026#34;]\u0026#39; - field: \u0026#39;warning\u0026#39; copy: \u0026#39;[warning]\u0026#39; - field: \u0026#39;notice\u0026#39; copy: \u0026#39;[notice]\u0026#39; Warning: Unlike an ArrayMapper, here the field must not be between [...].\nSee Reading from objects.\nBuilding an ObjectMapper To write a mapping to an object, you must use the object option, which will always be accompanied by the options class and expression.\nclass : determines the class to be used in the mapping. expression : allows you to write an expression that will be used in the mapping. fastmap: class: \u0026#39;Foo\\DTO\\Product\u0026#39; expression: \u0026#39;input\u0026#39; object: - field: \u0026#39;sku\u0026#39; copy: \u0026#39;[sku]\u0026#39; Warning: Unlike an ArrayMapper, here the field must not be between [...].\nSee Reading from objects.\nBuilding a ConditionalMapper To write a list of mappers that will only execute if a condition is met, you must use the conditional option, under which you can declare multiple Array (map) or Object (object) mappers, each protected by a condition.\nThe behaviour is similar to if ... else if ..., meaning only 1 of the mappers will be executed.\nfastmap: conditional: - condition: \u0026#39;keyExists(\u0026#34;sku\u0026#34;, input)\u0026#39; append: true # Optional. Merges this step\u0026#39;s output into the previous step\u0026#39;s result. map: # ... - condition: \u0026#39;keyExists(\u0026#34;identifier\u0026#34;, input)\u0026#39; append: true object: # ... </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/fast-map\/"
						},

						{
							value: "HTTP API",
							label: "<p> What is it ? Installation Basic usage Advanced usage Adding JWT Authorization Adding Basic HTTP Authorization What is it ? This package allows you to create an API that will serve multiple endpoints.\nThe goal is to be able to send data to these endpoints, to process it in a series of steps.\nBasic usage To define your HTTP API, you need to specify a root path, and one or multiple routes under that root:\nversion: \u0026#39;0.3\u0026#39; satellites: my_satellite: label: \u0026#39;Example of an api\u0026#39; filesystem: path: build composer: require: - \u0026#34;middlewares\/uuid:dev-master\u0026#34; - \u0026#34;middlewares\/base-path:dev-master\u0026#34; - \u0026#34;middlewares\/request-handler:dev-master\u0026#34; - \u0026#34;middlewares\/fast-route:dev-master\u0026#34; - \u0026#34;laminas\/laminas-diactoros\u0026#34; - \u0026#34;laminas\/laminas-httphandlerrunner\u0026#34; - \u0026#34;nyholm\/psr7-server\u0026#34; - \u0026#34;nyholm\/psr7\u0026#34; - \u0026#34;php-etl\/pipeline\u0026#34; - \u0026#34;php-etl\/satellite\u0026#34; - \u0026#34;php-etl\/api-runtime\u0026#34; - \u0026#34;php-etl\/mapping-contracts\u0026#34; http_api: name: \u0026#39;My HTTP API\u0026#39; # Optional path: \/my-api routes: - route: \/transform name: \u0026#39;A route to transform my products\u0026#39; # Optional method: \u0026#39;post\u0026#39; # Optional. Default: \u0026#34;post\u0026#34; # Possible values: \u0026#34;get\u0026#34;, \u0026#34;post\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;delete\u0026#34;, \u0026#34;patch\u0026#34;, \u0026#34;head\u0026#34; expression: \u0026#39;input\u0026#39; pipeline: steps: - fastmap: map: - field: \u0026#39;[sku]\u0026#39; copy: \u0026#39;[product_name]\u0026#39; - field: \u0026#39;[id]\u0026#39; copy: \u0026#39;[product_code]\u0026#39; - csv: loader: file_path: \u0026#39;output.csv\u0026#39; After building the satellite, start a server in the path build\/:\nbin\/satellite run:api build\/ You can then send POST requests containing the data to process to http:\/\/localhost:8000\/my-api\/transform\n# input: [ { product_name: \u0026#39;test_1\u0026#39;, product_code: 861 }, { product_name: \u0026#39;test_2\u0026#39;, product_code: 862 } ] # response: {\u0026#34;message\u0026#34;:{\u0026#34;accept\u0026#34;:4,\u0026#34;reject\u0026#34;:0,\u0026#34;error\u0026#34;:0},\u0026#34;server\u0026#34;:\u0026#34;my-computer.local\u0026#34;} # output.csv: sku;id test_1;861 test_2;862 Advanced usage Adding JSON Web Token (JWT) Authorization # ... composer: require: - \u0026#34;tuupola\/slim-jwt-auth\u0026#34; # ... http_api: authorization: jwt: secret: \u0026#39;mysecret\u0026#39; With this config, each requests will need the header Authorization:\nheader value Authorization Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6Ik[\u0026hellip;] The string after \u0026ldquo;Bearer\u0026rdquo; is the token, generated from the secret phrase. This site can be used to generate a token from your own secret: https:\/\/jwt.io\nAdding Basic HTTP Authorization # ... composer: require: - \u0026#34;tuupola\/slim-basic-auth\u0026#34; # ... http_api: authorization: basic: - user: john password: mypassword - user: bill password: otherpassword The basic node is an array, and can contain multiple user\/password pairs.\nWith this configuration, each requests will need the header Authorization:\nheader value Authorization Basic am9objpteXBhc3N3b3Jk The string after \u0026ldquo;Basic\u0026rdquo; is the combination user:password encoded in Base64.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/satellite\/http-api\/"
						},

						{
							value: "Zoho CRM",
							label: "<p> What is it? Installation Usage Building a loader Building a lookup What is it? This package includes classes to load data into Zoho CRM, using a custom connector.\nInstallation composer require php-etl\/zoho-crm-flow:\u0026#39;*\u0026#39; Usage Building a loader The package includes the following loader classes: ContactLoader, DealLoader, OrderLoader, ProductLoader.\ncustom: loader: use: \u0026#39;Kiboko\\Component\\Flow\\ZohoCRM\\ContactLoader\u0026#39; services: Kiboko\\Component\\Flow\\ZohoCRM\\ContactLoader: public: true arguments: - \u0026#39;@Kiboko\\Component\\Flow\\ZohoCRM\\Client\\Client\u0026#39; - \u0026#39;@Monolog\\Logger\u0026#39; Kiboko\\Component\\Flow\\ZohoCRM\\Client\\Client: arguments: - \u0026#39;example-zoho.com\u0026#39; # URL of the website - \u0026#39;@Kiboko\\Component\\Flow\\ZohoCRM\\Client\\AuthenticationMiddleware\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; Kiboko\\Component\\Flow\\ZohoCRM\\Client\\AuthenticationMiddleware: arguments: - \u0026#39;@GuzzleHttp\\Client\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;accounts.example-zoho.com\u0026#39; # OAuth host - \u0026#39;200USADNWBAKRAFZASD\u0026#39; # Client id - \u0026#39;e7c20hns0pxmzsa531hdt7c9\u0026#39; # Client secret - \u0026#39;p2in89sjdgfnwoc3ehe8q00r\u0026#39; # Access token - \u0026#39;n7g0a4xfqyemc61uertqplks\u0026#39; # Refresh token GuzzleHttp\\Client: ~ GuzzleHttp\\Psr7\\HttpFactory: ~ Monolog\\Logger: arguments: - \u0026#39;app\u0026#39; - [ \u0026#39;@Monolog\\Handler\\StreamHandler\u0026#39; ] Monolog\\Handler\\StreamHandler: arguments: - \u0026#39;var\/dev.log\u0026#39; # Path to the log file - 300 # Log level. 300 for Warning, 200 for Info... Building a lookup The package includes the following lookup classes, and each require a different criteria to search for corresponding entries.\nEntity to lookup Class Search criteria Contact Kiboko\\Component\\Flow\\ZohoCRM\\ContactLookup Email Order Kiboko\\Component\\Flow\\ZohoCRM\\OrderLookup Subject \u002b Store Product Kiboko\\Component\\Flow\\ZohoCRM\\ProductLookup Product code custom: transformer: use: \u0026#39;Kiboko\\Component\\Flow\\ZohoCRM\\ContactLookup\u0026#39; services: Kiboko\\Component\\Flow\\ZohoCRM\\ContactLookup: public: true arguments: - \u0026#39;@Kiboko\\Component\\Flow\\ZohoCRM\\Client\\Client\u0026#39; - \u0026#39;@Monolog\\Logger\u0026#39; - \u0026#39;@Symfony\\Component\\Cache\\Psr16Cache\u0026#39; - \u0026#39;@Acme\\Custom\\LookupMapper\u0026#39; # Your custom mapper class - \u0026#39;customer_id\u0026#39; # Index of the search criteria, in your line. # In the case of the ContactLookup, it should be an email. # Here we temporarily store the customer email in this field. # LookupMapper will then replace it with the actual ID. Kiboko\\Component\\Flow\\ZohoCRM\\Client\\Client: arguments: - \u0026#39;example-zoho.com\u0026#39; # URL of the website - \u0026#39;@Kiboko\\Component\\Flow\\ZohoCRM\\Client\\AuthenticationMiddleware\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; Kiboko\\Component\\Flow\\ZohoCRM\\Client\\AuthenticationMiddleware: arguments: - \u0026#39;@GuzzleHttp\\Client\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;@GuzzleHttp\\Psr7\\HttpFactory\u0026#39; - \u0026#39;accounts.example-zoho.com\u0026#39; # OAuth host - \u0026#39;200USADNWBAKRAFZASD\u0026#39; # Client id - \u0026#39;e7c20hns0pxmzsa531hdt7c9\u0026#39; # Client secret - \u0026#39;p2in89sjdgfnwoc3ehe8q00r\u0026#39; # Access token - \u0026#39;n7g0a4xfqyemc61uertqplks\u0026#39; # Refresh token GuzzleHttp\\Client: ~ GuzzleHttp\\Psr7\\HttpFactory: ~ Symfony\\Component\\Cache\\Psr16Cache: arguments: - \u0026#39;@Symfony\\Component\\Cache\\Adapter\\ApcuAdapter\u0026#39; Symfony\\Component\\Cache\\Adapter\\ApcuAdapter: ~ # Your custom mapper class Acme\\Custom\\LookupMapper: ~ Monolog\\Logger: arguments: - \u0026#39;app\u0026#39; - [ \u0026#39;@Monolog\\Handler\\StreamHandler\u0026#39; ] Monolog\\Handler\\StreamHandler: arguments: - \u0026#39;var\/dev.log\u0026#39; # Path to the log file - 300 # Log level. 300 for Warning, 200 for Info... Learn how to create your custom mapper class.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/zoho\/"
						},

						{
							value: "Execution",
							label: "<p>Once your PHP code is generated, it can be executed right away.\nIn the following paragraphs, you will find the method for executing the satellites depending on the adapter you have chosen.\nIf you built inside the filesystem Runs the pipeline that was compiled under src\/build\/:\nphp bin\/satellite run:pipeline src\/build\/ This command will run your satellite service located in a directory. The execution of your service may take several minutes, so please wait until the execution is completed.\nAfter compilation, check that src\/build\/output.csv has been created.\nIf you built as a Docker image docker run --rm -ti foo\/satellite-name:latest This command will run your satellite service you have previously built as a Docker image you named foo\/satellite-name:latest.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/getting-started\/execution\/"
						},

						{
							value: "State",
							label: "<p> What is it for? Installation Usage With RabbitMQ Using a service What is it for? The state feature allows you to manage the states advancement of your pipeline.\nInstallation This plugin is already integrated into the Satellite package, so you can\u0026rsquo;t require it with the composer.\nUsage When you configure your pipeline, you can add the configuration of this feature to your step configuration.\nFirst, you must use the state option.\nstate: # ... With RabbitMQ This feature supports sending to RabbitMQ instances.\nBasic configuration To enable a connection to your RabbitMQ application, you need at least 3 options which are host, vhost and topic.\nhost: this is the name of your host name vhost: this is the virtual host of your RabbitMQ instance topic: this is the name of the queue to which the rejects will be sent state: destinations: - rabbitmq: host: rabbitmq.example.com vhost: \/ topic: foo.rejects Additional options This feature additionally takes some options that can be used when configuring to your instance.\nuser: this is the username of your user password: this is the password of your user port: this is the port that your RabbitMQ application uses exchange: this is the name of the exchange to be used state: destinations: - rabbitmq: host: rabbitmq.example.com port: 5672 user: \u0026#39;guest\u0026#39; password: \u0026#39;guest\u0026#39; vhost: \/ topic: foo.rejects exchange: \u0026#39;amq.direct\u0026#39; Using a service It\u0026rsquo;s possible to use a service that has been previously defined in the pipeline or the workflow configuration.\nTo use a service, you just have to write the name of your service preceded by a @.\nstate: destinations: - \u0026#39;@App\\Service\\Bar\u0026#39; Warning : In the case where the states of your steps must all be sent to the same instance with a unique manager, you must use services.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/state\/"
						},

						{
							value: "FTP",
							label: "<p> What is it ? Installation Usage Building a loader Sample configuration FTP, File Transfer Protocol, is a protocol used to transfer files from a computer to a server or from a server to a computer.\nWhat is it ? The FTP plugin aims at integrating the files uploader into the Pipeline stack.\nInstallation This plugin is already integrated into the Satellite package, so you can\u0026rsquo;t require it with the composer.\nUsage Unlike the other plugins, the FTP plugin can only be used to load data.\nBuilding a loader To build a loader, you need to define a list of servers to which files will be sent and choose which files will be sent.\nConfiguring your servers Each server must have a host, a port (optional, use port 21 by default), the username and password to connect to the server and the base_path of the server where the files will be sent.\nftp: loader: servers: - host: \u0026#39;http:\/\/localhost\u0026#39; port: 21 # The default ftp port username: \u0026#39;root\u0026#39; password: \u0026#39;root\u0026#39; base_path: \/ It\u0026rsquo;s possible to activate the passive mode when connecting to a server with the passive_mode option.\nftp: loader: servers: - # ... passif_mode: true Configuring your files Next, you need to determine the specific path of each file you are going to upload and its content.\nftp: loader: put: - path: my\/file\/path content: \u0026#39;my_content\u0026#39; It\u0026rsquo;s possible to upload only those files that meet a condition using the if option.\nftp: loader: put: - # ... if: \u0026#39;@=input[\u0026#34;image\u0026#34;] !== null\u0026#39; Sample configuration ftp: loader: servers: - host: \u0026#39;http:\/\/localhost\u0026#39; port: 21 # The default ftp port username: \u0026#39;root\u0026#39; password: \u0026#39;root\u0026#39; base_path: \/ put: - path: my\/file\/path content: \u0026#39;my_content\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/ftp\/"
						},

						{
							value: "SFTP",
							label: "<p> What is it ? Installation Usage Building a loader Sample configuration FTP, File Transfer Protocol, is a protocol used to transfer files from a computer to a server or from a server to a computer.\nWhat is it ? The SFTP plugin aims at integrating the files uploader into the Pipeline stack.\nInstallation This plugin is already integrated into the Satellite package, so you can\u0026rsquo;t require it with the composer.\nUsage Unlike the other plugins, the FTP plugin can only be used to load data.\nBuilding a loader To build a loader, you need to define a list of servers to which files will be sent and choose which files will be sent.\nConfiguring your servers Each server must have a host, a port (optional, use port 21 by default), the username and password to connect to the server and the base_path of the server where the files will be sent.\nsftp: loader: servers: - host: \u0026#39;http:\/\/localhost\u0026#39; port: 21 username: \u0026#39;root\u0026#39; password: \u0026#39;root\u0026#39; base_path: \/ It\u0026rsquo;s possible to activate the passive mode when connecting to a server with the passive_mode option.\nsftp: loader: servers: - # ... passif_mode: true Configuring your files Next, you need to determine the specific path of each file you are going to upload and its content.\nsftp: loader: put: - path: my\/file\/path content: \u0026#39;my_content\u0026#39; It\u0026rsquo;s possible to upload only those files that meet a condition using the if option.\nsftp: loader: put: - # ... if: \u0026#39;@=input[\u0026#34;image\u0026#34;] !== null\u0026#39; Sample configuration sftp: loader: servers: - host: \u0026#39;http:\/\/localhost\u0026#39; port: 21 username: \u0026#39;root\u0026#39; password: \u0026#39;root\u0026#39; base_path: \/ put: - path: my\/file\/path content: \u0026#39;my_content\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/sftp\/"
						},

						{
							value: "JSON",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it ? Installation Usage Building an extractor Building a loader JSON (JavaScript Object Notation) is a lightweight format for data exchange.\nThis package also supports NDJSON and JSON-LD.\nWhat is it for? This plugin aims at integrating a JSON, NDJSON and JSON-LD extractor and loader into the Pipeline stack.\nInstallation In a Satellite project, add the JSON plugin this way:\ncomposer require php-etl\/json-plugin:\u0026#39;*\u0026#39; Usage Building an extractor To build an extractor, you need to specify the path of your file with the file_path option.\nYAML json: extractor: file_path: \u0026#39;input.json\u0026#39; Building a loader To build a loader, you need to specify the path to your file with the file_path option.\nYAML json: loader: file_path: \u0026#39;output.json\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/json\/"
						},

						{
							value: "Spreadsheet",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it ? Installation Usage Building an extractor Building a loader Advanced usage Skip one or more lines Splitting into several files XLSX is the file format used by Microsoft Excel spreadsheets.\nODS is the OpenDocument spreadsheet file format used by Libreoffice and OpenOffice.\nWhat is it for? The Spreadsheet plugin aims at integrating spreadsheet file formats (XLSX, ODS and CSV) into the Pipeline stack.\nInstallation In a Satellite project, add the spreadsheet plugin this way:\ncomposer require php-etl\/spreadsheet-plugin:\u0026#39;*\u0026#39; Usage Building an extractor To build an extractor, you need to specify the path of your file, the type of extractor to build, and the name of the sheet to read.\nThe different types of extractor supported are:\nexcel open_document csv Excel OpenDocument CSV spreadsheet: extractor: file_path: \u0026#39;input.xlsx\u0026#39; excel: sheet: \u0026#39;sheet2\u0026#39; spreadsheet: extractor: file_path: \u0026#39;input.ods\u0026#39; open_document: sheet: \u0026#39;sheet2\u0026#39; spreadsheet: extractor: file_path: \u0026#39;input.csv\u0026#39; csv: delimiter: \u0026#39;,\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; Building a loader To build a loader, you must specify the path of your file, the type of loader to build and the name of the sheet to write data into.\nThe different types of loader supported are:\nexcel open_document csv Excel OpenDocument CSV spreadsheet: loader: file_path: \u0026#39;output.xlsx\u0026#39; excel: sheet: \u0026#39;sheet2\u0026#39; spreadsheet: loader: file_path: \u0026#39;output.ods\u0026#39; open_document: sheet: \u0026#39;sheet2\u0026#39; spreadsheet: loader: file_path: \u0026#39;output.csv\u0026#39; csv: delimiter: \u0026#39;,\u0026#39; enclosure: \u0026#39;\u0026#34;\u0026#39; Advanced usage Skip one or more lines Your file may have a header of one or more lines, you must use the skip_lines option to get your pipeline to start extracting from the right row.\nExcel OpenDocument CSV spreadsheet: extractor: excel: # ... skip_lines: 2 spreadsheet: extractor: open_document: # ... skip_lines: 2 spreadsheet: extractor: csv: # ... skip_lines: 2 Note: This option is only available when building extractors\nSplitting into several files To limit the number of lines you will write into the output files, you can specify the max_lines option.\nExcel OpenDocument CSV spreadsheet: loader: excel: # ... max_lines: 20 spreadsheet: loader: open_document: # ... max_lines: 20 spreadsheet: loader: csv: # ... max_lines: 20 Note: this option is only available for loaders\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/spreadsheet\/"
						},

						{
							value: "SQL",
							label: "<p> What is it ? Installation Usage Database connection Building an extractor Building a lookup Building a ConditionalLookup Building a loader Building a ConditionalLoader Advanced usage Using params in your queries Using an unknown number of parameters Creating before and after queries SQL, Structured Query Language, is a language for manipulating databases.\nWhat is it ? The SQL plugin allows you to write your own SQL queries and use them into the Pipeline stack.\nInstallation Before installing the SQL plugin, you must verify that the PDO extension is installed on your environment.\ncomposer require php-etl\/sql-plugin:\u0026#39;*\u0026#39; If you want to use an engine like postgres, install ext-php_postgres on the computer. Add these lines to your pipeline to have an explicit error message if your SQL engine is not installed\nsql-to-csv: label: \u0026#39;SQLite to CSV simple\u0026#39; composer: require: - \u0026#34;ext-php_sqlite\u0026#34; Usage Database connection The SQL plugin uses the PDO extension and relies on its interface to access databases using the dsn, username and password parameters.\nThis connection must be present in any case, whether it be when defining the extractor, loader or lookup.\ncomposer: require: - \u0026#34;ext-php_mysql\u0026#34; pipeline: steps: sql: connection: dsn: \u0026#39;mysql:host=127.0.0.1;port=3306;dbname=kiboko\u0026#39; username: username password: password Options Persistent It is possible to specify options at the time of this connection using options. Currently, it is only possible to specify if the database connection should be persistent.\nsql: connection: # ... options: persistent: true Shared In some cases, you may need to pool connections to your database to avoid having to open and close a whole new connection for every operation the database needs to perform.\nsql: connection: # ... shared: true Building an extractor In the configuration of your extractor, you must write your query with the option query.\nsql: extractor: query: \u0026#39;SELECT * FROM table1\u0026#39; connection: dsn: \u0026#39;mysql:host=127.0.0.1;port=3306;dbname=kiboko\u0026#39; username: username password: password Building a lookup In some cases, you will need to perform lookups by joining data from input columns to columns in a reference dataset; this is called a lookup.\nIn the configuration of your lookup, you must write your query with the option query.\nThe merge option allows you to add data to your dataset, in a sense merging your actual dataset with your new data.\nThe map option comes from the FastMap plugin, feel free to read its documentation to understand how to use it.\nsql: lookup: query: \u0026#39;SELECT * FROM table2 WHERE bar = foo\u0026#39; merge: map: - field: \u0026#39;[options]\u0026#39; expression: \u0026#39;lookup[\u0026#34;name\u0026#34;]\u0026#39; connection: dsn: \u0026#39;mysql:host=127.0.0.1;port=3306;dbname=kiboko\u0026#39; username: username password: password Building a ConditionalLookup The conditional lookup is a lookup that takes conditions into account. Your lookup will be executed when each condition is met.\nAbout its configuration, you will find the same options as for the classic lookup, except that there is an additional condition option.\nsql: lookup: conditional: - condition: \u0026#39;@=input[\u0026#34;id\u0026#34;] \u0026gt; 2\u0026#39; query: \u0026#39;SELECT * FROM foo WHERE value IS NOT NULL AND id \u0026lt;= ?\u0026#39; parameters: identifier: value: \u0026#39;@=3\u0026#39; merge: map: - field: \u0026#39;[options]\u0026#39; expression: \u0026#39;lookup[\u0026#34;name\u0026#34;]\u0026#39; # ... Building a loader In the configuration of your loader, you must write your query avec l\u0026rsquo;option query.\nsql: loader: query: \u0026#39;INSERT INTO table1 VALUES (bar, foo, barfoo)\u0026#39; connection: dsn: \u0026#39;mysql:host=127.0.0.1;port=3306;dbname=kiboko\u0026#39; username: username password: password Building a ConditionalLoader The conditional loader is a loader that takes conditions into account. Your loader will be executed when each condition is met.\nAbout its configuration, you will find the same options as for the classic loader, except that there is an additional condition option.\nsql: loader: conditional: - condition: \u0026#39;@=input[\u0026#34;id\u0026#34;] \u0026gt; 2\u0026#39; query: \u0026#39;SELECT * FROM foo WHERE value IS NOT NULL AND id \u0026lt;= ?\u0026#39; parameters: identifier: value: \u0026#39;@=3\u0026#39; # ... Advanced Usage Using params in your queries Thanks to the SQL plugin, it is possible to write your queries with parameters.\nIf you write a prepared statement using named parameters (:param), your parameter\u0026rsquo;s key in the configuration will be the name of your parameter without the : :\nsql: loader: query: \u0026#39;INSERT INTO table1 VALUES (:value1, :value2, :value3)\u0026#39; parameters: value1: value: \u0026#39;@=input[\u0026#34;value1\u0026#34;]\u0026#39; value2: value: \u0026#39;@=input[\u0026#34;value3\u0026#34;]\u0026#39; value3: value: \u0026#39;@=input[\u0026#34;value3\u0026#34;]\u0026#39; # ... If you are using a prepared statement using interrogative markers (?), your parameter\u0026rsquo;s key in the configuration will be its position (starting from 1) :\nsql: loader: query: \u0026#39;INSERT INTO table1 VALUES (?, ?, ?)\u0026#39; parameters: 1: value: \u0026#39;@=input[\u0026#34;value1\u0026#34;]\u0026#39; 2: value: \u0026#39;@=input[\u0026#34;value3\u0026#34;]\u0026#39; 3: value: \u0026#39;@=input[\u0026#34;value3\u0026#34;]\u0026#39; # ... Using an unknown number of parameters In some cases, you may not know in advance how many parameters you will need to enter, for example if you are searching using an IN with many values.\nUsing from instead of value will bind as many parameters as there are values in the path.\nAnd use the expression inSql(path, parameter_name) to prepare the values in the query.\nsql: loader: query: \u0026#39;@=\u0026#34;SELECT * FROM category WHERE id \u0026#34; ~ inSql(input[\u0026#34;codes_list\u0026#34;], \u0026#34;identifier\u0026#34;) ~ \u0026#34;\u0026#39; parameters: identifier: from: \u0026#39;@=input[\u0026#34;codes_list\u0026#34;]\u0026#39; # ... If at runtime there are 4 values under [codes_list], this would be equivalent to writing:\nsql: loader: query: \u0026#39;SELECT * FROM category WHERE id IN (:identifier_0, :identifier_1, :identifier_2, :identifier_3)\u0026#39; parameters: identifier_0: value: \u0026#39;@=input[\u0026#34;codes_list\u0026#34;][0]\u0026#39; identifier_1: value: \u0026#39;@=input[\u0026#34;codes_list\u0026#34;][1]\u0026#39; identifier_2: value: \u0026#39;@=input[\u0026#34;codes_list\u0026#34;][2]\u0026#39; identifier_3: value: \u0026#39;@=input[\u0026#34;codes_list\u0026#34;][3]\u0026#39; # ... Creating before and after queries In some cases, you may need to run queries in order to best prepare for the execution of your pipeline.\nBefore queries Before queries will be executed before performing the query written in the configuration. Often, these are queries that set up the database.\nsql: before: queries: - \u0026#39;CREATE TABLE foo (id INTEGER NOT NULL, value VARCHAR(255) NOT NULL)\u0026#39; - \u0026#39;INSERT INTO foo (id, value) VALUES (1, \u0026#34;Lorem ipsum dolor\u0026#34;)\u0026#39; - \u0026#39;INSERT INTO foo (id, value) VALUES (2, \u0026#34;Sit amet consecutir\u0026#34;)\u0026#39; # ... After queries After queries will be executed after performing the query written in the configuration. Often, these are queries that clean up the database.\nsql: after: queries: - \u0026#39;DROP TABLE foo\u0026#39; # ... </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/sql\/"
						},

						{
							value: "Sylius",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it ? Installation Usage Connecting to Sylius Building an extractor Building a loader Advanced usage Filtering your search Sylius is a Headless E-commerce platform.\nWhat is it ? The Sylius plugin will enable Sylius connectivity to the Pipeline, in order to read and write from and to Sylius.\nInstallation composer require php-etl\/sylius-plugin:\u0026#39;*\u0026#39; Usage Connecting to Sylius To establish a connection to your Sylius API, you must specify its URL and some connection identifiers (client_id, secret, username, password).\nsylius: # ... client: api_url: \u0026#39;http:\/\/127.0.0.1:8001\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;api\u0026#39; password: \u0026#39;sylius-api\u0026#39; To retrieve these identifiers, go to the official documentation of Sylius.\nBuilding an extractor In the configuration of your extractor, you must specify the type of table you will be working on and which method you want to use to retrieve your data.\nThe list of available tables is quite long : channels, countries, carts, currencies, customers, exchangeRates, locales, orders, payments, paymentMethods, products, productAttributes, productAssociationTypes, productOptions, promotions, shipments, shippingCategories, taxCategories, taxRates, taxons, users, zones.\nFor each table, the following 3 methods are available :\nall : retrieves all data from a table get : retrieve a row from a table listPerPage : retrieves a set number of data from a table sylius: extractor: type: products method: all client: api_url: \u0026#39;http:\/\/127.0.0.1:8001\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;api\u0026#39; password: \u0026#39;sylius-api\u0026#39; Building a loader In the configuration of your extractor, you must specify the type of table you are going to work on and which method you want to use to insert your data.\nThe list of available tables is quite long : channels, countries, carts, currencies, customers, exchangeRates, locales, orders, payments, paymentMethods, products, productAttributes, productAssociationTypes, productOptions, promotions, shipments, shippingCategories, taxCategories, taxRates, taxons, users, zones.\nFor each table, the following 2 methods are available:\ncreate : insert a row into the table delete : delete a row from the table sylius: loader: type: products method: create client: api_url: \u0026#39;http:\/\/127.0.0.1:8001\u0026#39; client_id: \u0026#39;414yc7d9mnk044ko4wswgw80o8ssw80gssos488kk8ogss40ko\u0026#39; secret: \u0026#39;4k8ee6n44m4gkkg0coc8o4w4coscw0w4cg0wg8sc0wsk0sw8gs\u0026#39; username: \u0026#39;api\u0026#39; password: \u0026#39;sylius-api\u0026#39; Advanced Usage Filtering your search In some cases, you may only want to retrieve data that matches specific criteria.\nWhen performing a search, you need to specify certain options :\nfield : the field you want to search operator : the operator of your search value : the value of the field you want to search Other options are available but are not essential in your search :\nscope : channel in which you search locale : code of the locale you are looking for sylius: extractor: # ... search: - { field: enabled, operator: \u0026#39;=\u0026#39;, value: true } </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/sylius\/"
						},

						{
							value: "Prestashop",
							label: "<p> What is it? Installation Usage Building an extractor Building a loader Prestashop is an e-commerce platform. Read more about its API resources, options, and how to open the API access.\nWhat is it? The Prestashop plugin aims at connecting a Prestashop instance through its API using a pipeline.\nCurrently, the following resources are supported by the plugin: categories, combinations, manufacturers, product_features, product_feature_values, product_options, product_option_values, products, shops, stock_availables, suppliers, tax_rule_groups, tax_rules.\nInstallation composer require php-etl\/prestashop-plugin:\u0026#39;*\u0026#39; Usage Building an extractor prestashop: client: url: \u0026#39;https:\/\/prestashop.example.com\u0026#39; # the base URL of your Prestashop main website api_key: \u0026#39;abc1234\u0026#39; # the access key to the API extractor: type: \u0026#39;products\u0026#39; # the resource type you wish to retrieve method: \u0026#39;all\u0026#39; # the retrieval method, currently it should always be \u0026#39;all\u0026#39;. Optional parameters: extractor: # ... options: columns: # Specify the fields you wish to retrieve - \u0026#39;id\u0026#39; # by default all the fields will be retrieved, which can have - \u0026#39;product_type\u0026#39; # an impact on the performance of your pipelines - \u0026#39;price\u0026#39; filter: # filter the result based on a value, or a range of values id: \u0026#39;[1,10]\u0026#39; sorters: # sorting fields and their direction id: \u0026#34;ASC\u0026#34; id_shop: 1 # identifier of the shop containing the data you want to extract data from id_group_shop: 1 price: # list the price requests you want the API to calculate for you my_price: # each element in this list is an individual price request you # will ask, that will be retrieved through an individual field quantity: 25 # the price request may contain any of the following parameters: # country, state, postcode, currency, group, quantity, product_attribute, # decimals, use_tax, use_reduction, only_reduction, use_ecotax # for more details, see https:\/\/devdocs.prestashop-project.org\/8\/webservice\/tutorials\/advanced-use\/specific-price\/ languages: Example, with a list of identifiers Example, with a range of identifiers extractor: # ... options: languages: [ 1, 2, 3 ] # list of ids of the languages to retrieve. extractor: # ... options: languages: # a range of ids of the languages to retrieve. from: 1 to: 5 Read the PrestaShop Documentation for more details.\nBuilding a loader prestashop: client: url: \u0026#39;https:\/\/prestashop.example.com\u0026#39; api_key: \u0026#39;abc1234\u0026#39; loader: type: \u0026#39;products\u0026#39; # the resource type to write to method: \u0026#39;upsert\u0026#39; # the method to use, available methods are \u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;upsert\u0026#39;. # \u0026#39;create\u0026#39; will only create products and fail if the product already exists # \u0026#39;update\u0026#39; will only update products and fail if the product does not exist # \u0026#39;upsert\u0026#39; will try to update if the product already exists or create the product if it does not exist Optional parameters: loader: # ... options: id_shop: 1 # id of the shop id_group_shop: 1 # id of the shop group Read the PrestaShop Documentation for more details.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/prestashop\/"
						},

						{
							value: "Filtering, drop or reject",
							label: "<p> What is it? Installation Usage Dropping a line Rejecting a line What is it? The Filtering plugin can reject data, which prevents it from advancing in the pipeline, based on a condition.\nInstallation This plugin is already integrated into the Satellite package, so you cant require it with composer.\nUsage Dropping a line For example, this will ignore the line if the field \u0026ldquo;identifier\u0026rdquo; is missing, using the array expression keyExists:\n- filter: drop: - when: \u0026#39;@=!keyExists(\u0026#34;identifier\u0026#34;, input)\u0026#39; Rejecting a line This is equivalent to dropping a line, but when paired with a rejection configuration you will be able to log information about the dropped line.\nThis will ignore a line where the field \u0026ldquo;image\u0026rdquo; is empty, and store that data in some destination:\n- filter: reject: - when: \u0026#39;@=input[\u0026#34;identifier\u0026#34;] === null\u0026#39; rejection: destinations: # ... </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/filtering\/"
						},

						{
							value: "Batch",
							label: "<p> What is it? Installation Usage Forking a line Merging multiple lines What is it? The Batch plugin can split a single line of data into multiple ones, or can merge multiple lines into a single one.\nInstallation This plugin is already integrated into the Satellite package, so you cant require it with composer.\nUsage Forking a line fork splits data into multiple lines.\nIn the following example, we have one line containing 2 fields: an id, and images which contains multiple values. Instead we want to have multiple lines, each containing a single image along with the id.\nOur example input looks like this:\n[{\u0026#34;images\u0026#34;: [\u0026#34;one.jpg\u0026#34;, \u0026#34;two.jpg\u0026#34;, \u0026#34;three.jpg\u0026#34;], \u0026#34;id\u0026#34;: 15}] We\u0026rsquo;ll use the \u0026ldquo;fork\u0026rdquo; option to split the lines for each value under images:\nYAML configuration interpreted code batch: fork: foreach: \u0026#39;@=input[\u0026#34;images\u0026#34;]\u0026#39; do: \u0026#39;@={ id: input[\u0026#34;id\u0026#34;], image: item }\u0026#39; $results = []; foreach ($input[\u0026#34;images\u0026#34;] as $key =\u0026gt; $item) { $results[] = [\u0026#34;id\u0026#34; =\u0026gt; $input[\u0026#34;id\u0026#34;], \u0026#34;image\u0026#34; =\u0026gt; $item]; } The result will be:\n[{\u0026#34;id\u0026#34;: 15, \u0026#34;image\u0026#34;: \u0026#34;one.jpg\u0026#34;}] [{\u0026#34;id\u0026#34;: 15, \u0026#34;image\u0026#34;: \u0026#34;two.jpg\u0026#34;}] [{\u0026#34;id\u0026#34;: 15, \u0026#34;image\u0026#34;: \u0026#34;three.jpg\u0026#34;}] Merging multiple lines merge concatenates many lines traversing the pipeline into fewer lines.\nThis can be useful if the targeted API can handle many batches of data in a single payload, like Akeneo for example.\nOur example input looks like this:\n[{\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;}] [{\u0026#34;lorem\u0026#34;: \u0026#34;ipsum\u0026#34;}] [{\u0026#34;ga\u0026#34;: \u0026#34;bu\u0026#34;}] [{\u0026#34;zo\u0026#34;: \u0026#34;meu\u0026#34;}] [{\u0026#34;bla\u0026#34;: \u0026#34;bli\u0026#34;}] We\u0026rsquo;ll use the \u0026ldquo;merge\u0026rdquo; option. size dictates the maximum number of lines to concatenate:\nYAML configuration batch: merge: size: 2 When the number of item reaches size, the merge will be applied to the next lines, and so on.\nThe output will be:\n[{\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;},{\u0026#34;lorem\u0026#34;: \u0026#34;ipsum\u0026#34;}] [{\u0026#34;ga\u0026#34;: \u0026#34;bu\u0026#34;},{\u0026#34;zo\u0026#34;: \u0026#34;meu\u0026#34;}] [{\u0026#34;bla\u0026#34;: \u0026#34;bli\u0026#34;}] </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/batch\/"
						},

						{
							value: "Clouds",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/cloud\/"
						},

						{
							value: "Gyroscops",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/"
						},

						{
							value: "Usage",
							label: "<p>Gyroscops also allows you to have your satellites stored in the cloud.\nThanks to the cloud executable provided by the package php-etl\/satellite, you can manage your satellites quickly and easily thanks to command lines.\nRequirements Before you start, make sure you have installed the utility in your project.\nIf you haven\u0026rsquo;t already done so, simply run this command:\ncomposer require php-etl\/satellite:\u0026#39;*\u0026#39; Log into the API The login command is used to establish a connection with the Gyroscops API, allowing access to the various functionalities. Before executing this command, make sure you have the necessary identification information to hand.\nbin\/cloud login The service may ask you to select your organization and your workspace.\nOptions -u, --url: Base URL of the cloud instance [default: \u0026ldquo;https:\/\/app.gyroscops.com\u0026rdquo;] --beta: Shortcut to set the cloud instance to https:\/\/beta.gyroscops.com --ssl|--no-ssl: Enable or disable SSL --help: Display help for the given command See the following sections of this documentation for details of the various commands.\nCreate your satellite The create command is used to create a satellite associated with your account.\nphp bin\/cloud create \u0026lt;path\/to\/satellite.yaml\u0026gt; Options -u, --url: Base URL of the cloud instance [default: \u0026ldquo;https:\/\/app.gyroscops.com\u0026rdquo;] --beta: Shortcut to set the cloud instance to https:\/\/beta.gyroscops.com --ssl|--no-ssl: Enable or disable SSL --help: Display help for the given command Once you have created your satellite, you can access its configuration from the interface by following these steps:\nEnter the following URL in the address bar: https:\/\/app.gyroscops.com (or https:\/\/beta.gyroscops.com) Log in with your credentials Update your satellite The update command is used to update a given satellite.\nphp bin\/cloud update \u0026lt;path\/to\/satellite.yaml\u0026gt; Options -u, --url: Base URL of the cloud instance [default: \u0026ldquo;https:\/\/app.gyroscops.com\u0026rdquo;] --beta: Shortcut to set the cloud instance to https:\/\/beta.gyroscops.com --ssl|--no-ssl: Enable or disable SSL --help: Display help for the given command Remove your satellite The remove command is used to remove a given satellite.\nphp bin\/cloud remove \u0026lt;path\/to\/satellite.yaml\u0026gt; Options -u, --url: Base URL of the cloud instance [default: \u0026ldquo;https:\/\/app.gyroscops.com\u0026rdquo;] --beta: Shortcut to set the cloud instance to https:\/\/beta.gyroscops.com --ssl|--no-ssl: Enable or disable SSL --help: Display help for the given command Other commands In addition to the main commands we have already explored, this command line utility offers a number of additional features. These commands can be useful in a variety of situations.\nFor a list of these commands, use the following command:\nbin\/cloud list </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/cloud\/usage\/"
						},

						{
							value: "Core-Concepts",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/core-concept\/"
						},

						{
							value: "Connectivities",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/connectivity\/"
						},

						{
							value: "Getting-Starteds",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/getting-started\/"
						},

						{
							value: "Features",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/"
						},

						{
							value: "Satellite Expression Language",
							label: "<p> What is it ? Installation Usage List of available functions What is it ? This package extends the ExpressionLanguage component of Symfony to compile and evaluate file and environment variables.\nInstallation This package is already integrated into the Satellite package, so you can\u0026rsquo;t require it with the composer.\nUsage To use the functions provided in this package, you need to add the expression_language key to your plugin configuration and use the Kiboko\\Component\\Satellite\\ExpressionLanguage\\Provider Provider.\nexpression_language: - Kiboko\\Component\\Satellite\\ExpressionLanguage\\Provider To determine that a value in your configuration will be a language expression, you must use the @ annotation.\nfoo: \u0026#39;@=env(\u0026#34;MY_ENVIRONMENT_VARIABLE\u0026#34;)\u0026#39; List of available functions Name Description env(string name): \u0060string false\u0060 envAsFile(string name): string Create a file whose name is an environment variable file(string name): string Create a file base64Decode(string name): \u0060string false\u0060 temporaryFile(string name): resource Create a temporary file inSql(array path, string parameterName): string Writes \u0026ldquo;IN (\u0026hellip;)\u0026rdquo; with as many parameters as there are values under path, in the format: :parameterName_0, :parameterName_1\u0026hellip; To be used in a SQL query when searching among an unknown number of values. </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/expression-language\/satellite-expression-functions\/"
						},

						{
							value: "Array Expression Language",
							label: "<p> What is it ? Installation Usage List of available functions Generic functions Functions that can be used with reduce Functions that can be used with map What is it ? This package extends the ExpressionLanguage component of Symfony to compile and evaluate arrays with custom functions.\nInstallation composer require php-etl\/array-expression-language Usage To use the functions provided in this package, you need to add the expression_language key to your plugin configuration and use the Kiboko\\Component\\ArrayExpressionLanguage\\ArrayExpressionLanguageProvider Provider.\nexpression_language: - Kiboko\\Component\\ArrayExpressionLanguage\\ArrayExpressionLanguageProvider To determine that a value in your configuration will be a language expression, you must use the @ annotation.\nfoo: \u0026#39;@=map(input[\u0026#34;attributes\u0026#34;], extractData(\u0026#34;[fr_FR][data]\u0026#34;))\u0026#39; List of available functions Generic functions Name Description firstKey(array input): int|string|null Gets the first key of an array lastKey(array input): int|string|null Gets the last key of an array keyExists(string|int key, array input): bool Checks if the given key or index exists in the array merge(array|list \u0026hellip;inputs): array Merge one or more arrays count(Countable|array input ): int Count all elements in an array, or something in an object combine(list\u0026lt;int|string\u0026gt; keys, list\u0026lt;mixed\u0026gt; values ): array Creates an array by using one array for keys and another for its values map(callable callback, iterable input ): iterable Copy the iterator into an array iterableToArray(Traversable iterator, bool useKeys = true ): array Applies the callback to the elements of the given iterable reduce(iterable input, closure callback): string Iteratively reduce the iterable to a single value using a callback function list(int length, mixed value): iterable Fill an array with values intersect(array array, array \u0026hellip;arrays): array Computes the intersection of arrays filterList(string iterator, string callback): FilterIterator Filters elements of an array using a callback function mapValues(array input, array{pattern: replacement} values): array Finds multiple matches in the input and replaces them with a value, with the format {pattern: replacement, pattern: replacement ... } implode(string $separator, array $array): string Turns a list into a string Closures that can be provided to reduce Name Description join(string separator): closure Join array elements with a string Closures that can be provided to map Name Description extractData(string path): closure Retrieves the value of a key in an array or the property of an object </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/expression-language\/array-expression-functions\/"
						},

						{
							value: "String Expression functions",
							label: "<p> What is it for? Installation Usage List of available functions Generic functions Functions that can be used with reduce Functions that can be used with map What is it for? This package extends the ExpressionLanguage component of Symfony to compile and evaluate arrays with custom functions.\nInstallation composer require php-etl\/string-expression-language Usage To use the functions provided in this package, you need to add the expression_language key to your plugin configuration and use the Kiboko\\Component\\ArrayExpressionLanguage\\ArrayExpressionLanguageProvider Provider.\nexpression_language: - Kiboko\\Component\\StringExpressionLanguage\\StringExpressionLanguageProvider To determine that a value in your configuration will be a language expression, you must use the @ annotation.\nfoo: \u0026#39;@=dateTime(input[\u0026#34;updated_at\u0026#34;], \u0026#34;YYYY-MM-ddTHH:ii:ss\u0026#34;, \u0026#34;Europe\/Paris\u0026#34;)\u0026#39; List of available functions Name Description format(string format, mixed \u0026hellip;inputs): string Formats a string using the sprintf syntax trim(string input): string Trims whitespaces from a string capitalize(string input): string Makes a string\u0026rsquo;s first character uppercase toLowerCase(string input): string Makes a string lowercase search(string input, int offset, ?int length = null): string Returns part of a string toUpperCase(string input): string Makes a string uppercase formatNumber(float num, int decimals = 0, ?string decimal_separator = \u0026ldquo;.\u0026rdquo;, ?string thousands_separator = \u0026ldquo;,\u0026rdquo;): string Formats a number with grouped thousands indexOf(string haystack, string needle, int offset = 0): int|false Finds the position of the first occurrence of a substring in a string replace(string search, string replace, string input): string Replaces the search values in the string by the replace stripHtml(string string, array|string|null allowed_tags = null): string Strips HTML and PHP tags from a string decode(string string, array|string|null allowed_tags = null): mixed Decodes a JSON string replaceByExpression(string|array pattern, string|array replacement, string|array subject, int limit = -1, int \u0026amp;count = null): string|array|null Performs a regular expression search and replace capitalizeWords(string string, string separators = \u0026quot; \\t\\r\\n\\f\\v\u0026quot;): string Uppercases the first character of each word in a string removeWhitespaces(string string, string characters = \u0026quot; \\n\\r\\t\\v\\x00\u0026quot;): string Strips whitespace (or other characters) from the end of a string splitIntoArray(string separator, string string): array Splits a string by a string fileName(string path): string Extracts the file name from the path name dateTime(string dateTime, string format, string timezone = \u0026lsquo;UTC\u0026rsquo;): date Creates a date object from a formatted date formatDate(date dateTime, string format): string Transforms a date object into a formatted date string now(string timezone): string Returns a new \\DateTime object with the given timezone convertCharCode(string text, string sourceCharCode, string destinationCharCode): string Converts a string from one character encoding to another asFloat(string value): string Converts the value into a float number asInteger(string value): string Converts the value to an integer asString(string value): string Converts the value into a string truncate(string input, int limit): string Truncates the value. If the limit is 10 and the input goes above that limit, 9 characters will be kept and  will be added at the end. </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/feature\/expression-language\/string-expression-functions\/"
						},

						{
							value: "Frameworks",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/framework\/"
						},

						{
							value: "Metadata",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] What is it about? A metadata is a set of data that describe and gives information about other data. To sum up, it is an abbreviated representation of the data to which they refer.\nThis component aims at describing data structures in order to help other packages to auto-configure and handle data transformation and data manipulation.\nInstallation To use this package in your application, require it via composer:\ncomposer require php-etl\/metadata Use this package to read metadata of existing code In order to read the metadata of existing PHP code, you may use the automatic type guesser. It can be initialised with the following code:\n\u0026lt;?php use Kiboko\\Component\\Metadata\\TypeGuesser; use Phpactor\\Docblock\\DocblockFactory; use PhpParser\\ParserFactory; $typeGuesser = new TypeGuesser\\CompositeTypeGuesser( new TypeGuesser\\Native\\NativeTypeGuesser(), new TypeGuesser\\Docblock\\DocblockTypeGuesser( (new ParserFactory())-\u0026gt;create(ParserFactory::ONLY_PHP7), new DocblockFactory() ) ); Then, use the instance as a functor to automatically discover the types metadata.\nExample of a DTO class metadata fetcher:\n\u0026lt;?php use Kiboko\\Component\\Metadata; use Kiboko\\Component\\Metadata\\TypeGuesser\\TypeGuesserInterface; \/** @var TypeGuesserInterface $guesser *\/ class Person { public string $firstName; public string $lastName; public ?string $job; } $classOrObject = new \\ReflectionClass(\\Person::class); \/** @var Metadata\\ClassTypeMetadata $metadata *\/ $metadata = (new Metadata\\ClassTypeMetadata($classOrObject-\u0026gt;getShortName(), $classOrObject-\u0026gt;getNamespaceName())) -\u0026gt;addProperties(...array_map( function(\\ReflectionProperty $property) use($classOrObject, $guesser) { return new Metadata\\PropertyMetadata( $property-\u0026gt;getName(), ...$guesser($classOrObject, $property) ); }, $classOrObject-\u0026gt;getProperties(\\ReflectionProperty::IS_PUBLIC) ) ); Automatic class metadata guessing In order to simplify the class metadata building, there is a metadata guesser you can use to ease the building of metadata.\n\u0026lt;?php use Kiboko\\Component\\Metadata; \/** @var Metadata\\ClassMetadataBuilder $metadataBuilder *\/ $metadataBuilder = new Metadata\\ClassMetadataBuilder( new Metadata\\PropertyGuesser\\ReflectionPropertyGuesser($typeGuesser), new Metadata\\MethodGuesser\\ReflectionMethodGuesser($typeGuesser), new Metadata\\FieldGuesser\\FieldGuesserChain( new Metadata\\FieldGuesser\\PublicPropertyFieldGuesser(), new Metadata\\FieldGuesser\\VirtualFieldGuesser() ), new Metadata\\RelationGuesser\\RelationGuesserChain( new Metadata\\RelationGuesser\\PublicPropertyUnaryRelationGuesser(), new Metadata\\RelationGuesser\\PublicPropertyMultipleRelationGuesser(), new Metadata\\RelationGuesser\\VirtualRelationGuesser() ) ); $metadata = $metadataBuilder-\u0026gt;buildFromFQCN(\u0026#39;FooBarBundle\\\\Entity\\\\Foo\u0026#39;); Documentation To go further and see the DTO structure, check the object reference.\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/framework\/metadata\/"
						},

						{
							value: "Configurator Contracts",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/framework\/contracts\/configurator\/"
						},

						{
							value: "Contracts",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] Code contracts Introduction Code contracts are a set of abstraction interfaces made to help you build compatible code between all your pipelines, using common semantics.\nInstallation Contracts are provided as separate packages, so you can install only the ones your projects really need:\ncomposer require php-etl\/contracts composer require php-etl\/configurator-contracts composer require php-etl\/discovery-contracts composer require php-etl\/function-contracts composer require php-etl\/mapping-contracts composer require php-etl\/messenger-contracts composer require php-etl\/pipeline-contracts composer require php-etl\/reporting-contracts Usage The abstractions in those packages are useful to achieve loose coupling and interoperability. By using the provided interfaces as type hints, you are able to build any implementations that match the contracts. It could be a native Gyroscops component, or another package provided by the PHP community at large.\nDesign principles Contracts are split by domain, each into their own sub-namespaces Contracts are small and consistent sets of PHP interfaces Package php-etl\/contracts This package is a meta-package, containing all the packages described in the next paragraphs.\nPackage php-etl\/configurator-contracts This package is for packages describing their own .\nSee Configurator Contracts\nPackage php-etl\/discovery-contracts This package is for packages built for discovering the structure of the data and the API endpoints.\nGet more info at the Discovery documentation\nPackage php-etl\/function-contracts This package is for packages built for declaring and executing serverless functions\/lambda in the cloud.\nGet more info at the Satellite documentation\nPackage php-etl\/mapping-contracts This package is for packages built for declaring data mapping and data transformation.\nGet more info at the Fast Map documentation\nPackage php-etl\/messenger-contracts This package is for packages built for declaring application messaging services.\nPackage php-etl\/pipeline-contracts This package is for packages built for declaring data pipelines, using the Extract-Transform-Load pattern.\nGet more info at the Pipeline documentation\nPackage php-etl\/reporting-contracts This package is for packages built for managing logging and reporting of execution states and results.\nGet more info at the Dashboard documentation\n</p>",
							url:"https:\/\/php-etl.github.io\/documentation\/framework\/contracts\/"
						},

						{
							value: "Promise",
							label: "<p> FEATURE STATE: Gyroscops 0.1 [alpha] Definition of a Promise A promise represents a single result of an asynchronous operation.\nTwo operations are called asynchronous when they are independent, i.e. when the second operation does not need to wait for the first to finish before starting.\nThis object allows you to synchronise two (or more) actions that take place in time but not at the same speed.\nCallbacks The then method records reminders to receive the possible value of a promise, and the failure method represents the reason why it cannot be kept.\n\u0026lt;?php use Kiboko\\Component\\Promise\\Promise; $promise = new Promise(); $promise -\u0026gt;then(function ($value) { echo \u0026#34;Hello, \u0026#34;.$value; }) -\u0026gt;failure(function (\\Exception $exception) { echo \u0026#39;Oups, error : \u0026#39;.$exception; }) ; Resolving a promise Promises are fulfilled using the resolve($value) method.\n\u0026lt;?php $promise-\u0026gt;resolve(\u0026#39;world\u0026#39;); \/\/ Outputs \u0026#39;Hello, world\u0026#39; Promise failure Promises are failed using the fail($exception) method.\n\u0026lt;?php $promise-\u0026gt;fail(new Exception(\u0026#39;Something went wrong\u0026#39;)); \/\/ Outputs \u0026#39;Oups, error : Exception: Something went wrong\u0026#39; </p>",
							url:"https:\/\/php-etl.github.io\/documentation\/framework\/promise\/"
						},

						{
							value: "Categories",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/categories\/"
						},

						{
							value: "Tags",
							label: "<p></p>",
							url:"https:\/\/php-etl.github.io\/documentation\/tags\/"
						},

					];
					$( "#search" ).autocomplete({
						source: projects
					})
					.data( "ui-autocomplete" )._renderItem = function( ul, item ) {
						return $( "<li>" )
						.append( "<a href=" + item.url + " + \" &quot;\" +  >" + item.value + "</a>" + item.label )
						.appendTo( ul );
					};
					});
				</script>
			</div>
		</div>
	</div>
</div>
<!-- /banner -->
    </header>
    <!-- /header -->





  <section class="section">
    <div class="container">
      <div class="row">
        <div class="offset-2 col-8">
          <div class="section px-3 bg-white shadow text-center">
          <h2 class="mb-4">A data-centric framework for the cloud</h2>
          <p class="mb-6"><p>A cloud-friendly framework built for synchronizing your applications over the Internet.
Built to take advantage of the PHP ecosystem.</p>
<p>Build your data flows around APIs, message queues flat files or search engines to make them work
together smoothly. With integrated reporting and logging, get insights on what is going on and
keep control.</p>
</p>
            <a href="getting-started" class="btn btn-info"><i class="ti ti-map-alt"></i>&nbsp; Getting started</a>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- topics -->
  <section class="section">
    <div class="container">
      <div class="row justify-content-center">
        <div class="col-12 text-center">
          <h2 class="section-title section-dark">Find your answer by subject</h2>
        </div>
        <!-- topic-item -->

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/core-concept/satellite/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-lambda icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#lambda"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">Satellites</h3>
            <p class="mb-0">Generated satellites for data stream processing in the cloud</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/core-concept/satellite/pipeline/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-pipeline icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#pipeline"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">Pipeline</h3>
            <p class="mb-0">Data stream processing at high rate and low memory consuming</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/core-concept/satellite/http-hook/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-pipeline icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#pipeline"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">HTTP Hook</h3>
            <p class="mb-0">Data stream processing at high rate and low memory consuming</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/core-concept/satellite/http-api/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-pipeline icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#pipeline"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">HTTP API</h3>
            <p class="mb-0">Data stream processing at high rate and low memory consuming</p>
          </a>
        </div>

      </div>
    </div>
  </section>
  <!-- /topics -->

  <!-- topics -->
  <section class="section">
    <div class="container">
      <div class="row justify-content-center">
        <div class="col-12 text-center">
          <h2 class="section-title section-dark">Find the plugin for your data stores</h2>
        </div>
        <!-- topic-item -->

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/custom/lookup_mapper/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-settings icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">Lookup mapper</h3>
            <p class="mb-0">Learn how to write a custom mapper</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/akeneo/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-akeneo icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#akeneo"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">Akeneo</h3>
            <p class="mb-0">Connect your Akeneo PIM through pipelines</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/magento-2/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <h3 class="mb-3 mt-0">Magento 2</h3>
            <p class="mb-0">Read from and write to a Magento 2 site.</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/csv/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-csv icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#csv"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">CSV</h3>
            <p class="mb-0">Read and write CSV files in any format</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/custom/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-settings icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">Custom connector</h3>
            <p class="mb-0">Read transform and write files in any format</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/fast-map/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-fastmap icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#fastmap"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">Fast Map</h3>
            <p class="mb-0">Data transformation and serialization, with compiled and static mappers</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/zoho/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <h3 class="mb-3 mt-0">Zoho CRM</h3>
            <p class="mb-0">Read from and write to a Zoho CRM.</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/ftp/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-cloud-up icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">FTP</h3>
            <p class="mb-0">Transfer files to a remote FTP location</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/sftp/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-cloud-up icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">SFTP</h3>
            <p class="mb-0">Transfer files to a remote secured SFTP location</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/json/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-package icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">JSON</h3>
            <p class="mb-0">Read and write JSON files through your pipelines</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/spreadsheet/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-layout-grid3 icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">Spreadsheet</h3>
            <p class="mb-0">Read and write Excel or OpenDocument files</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/sql/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">

            <i class="ti-server icon text-primary d-block mb-4"></i>


            <h3 class="mb-3 mt-0">SQL</h3>
            <p class="mb-0">Process data from SQL data stores in your pipelines</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/sylius/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <i class="logo-sylius icon text-primary d-block mb-4">
              <svg>
                <use xlink:href="sprites.svg#sylius"></use>
              </svg>
            </i>

            <h3 class="mb-3 mt-0">Sylius</h3>
            <p class="mb-0">Connect your Sylius e-commerce through pipelines</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/prestashop/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <h3 class="mb-3 mt-0">Prestashop</h3>
            <p class="mb-0">Read from and write to a PrestaShop site.</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/filtering/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <h3 class="mb-3 mt-0">Filtering, drop or reject</h3>
            <p class="mb-0">Drop or reject data based on conditions.</p>
          </a>
        </div>

        <div class="col-lg-4 col-sm-6 mb-4">
          <a href="https://php-etl.github.io/documentation/connectivity/batch/" class="hp-push px-4 py-5 bg-white shadow text-center d-block match-height">


            <h3 class="mb-3 mt-0">Batch</h3>
            <p class="mb-0">Fork a single line into multiple lines, or merge multiple lines into one.</p>
          </a>
        </div>

      </div>
    </div>
  </section>
  <!-- /topics -->



  <!-- call to action -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <div class="section px-3 bg-white shadow text-center">
          <h2 class="mb-4">Didn&rsquo;t find an answer to your question?</h2>
          <p class="mb-4">You can reach our sales team we will find together the best way to provide you support.</p>


          <a href="mailto:sales@gyroscops.com" class="btn btn-primary">contact us</a>


          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- /call to action -->




    <!-- footer -->
<footer class="section pb-4">
  <div class="container">
    <div class="row align-items-center">
      <div class="col-md-8 text-md-left text-center">
       <p class="mb-md-0 mb-4"></p>
      </div>
      <div class="col-md-4 text-md-right text-center">
        <ul class="list-inline">

        </ul>
      </div>
    </div>
  </div>
</footer>
<!-- /footer -->

<!-- Main Script -->

<script src="https://php-etl.github.io/documentation/js/script.min.js"></script>
  </body>

</html>
